{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Let's Talk with Someone : (RAG) - Using GPT2 LLM]\n",
    "\n",
    "st125214 - Maung Maung Kyi Tha\n",
    "\n",
    "Practical application of RAG (Retrieval-Augmented Generation) techniques in Langchain framework to augment the chatbot that specializes in answering questions related to a person, in this case, Mr. Bill Gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Import Languagechain and its components\n",
    "from langchain.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Alternate Imports\n",
    "# from langchain.chains.retrieval import create_retrieval_chain\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# setting device to GPU cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Seet my seed\n",
    "SEED = 75\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Making sure we get the same results on each run\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Disable user warnings for neater output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to base on a person, Mr. Bill Gates, Founder of Microsoft, in this task.\n",
    "\n",
    "The following licture and information were collected and used as relevant sources about Bill Gates.\n",
    "\n",
    "1. Bill Gates, with Nathan Myhrvold and Peter Rinearson - The Road Ahead, Penguin Publishing, 1995\n",
    "2. Bill Gates Resume.pdf (curated and prepared from the wikipaedia web site )\n",
    "3. Wikipedia - https://en.wikipedia.org/wiki/Bill_Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Documents (PDFs & Web Data)\n",
    "\n",
    "def load_documents(pdf_paths): #, web_links):\n",
    "    documents = []\n",
    "    \n",
    "    # Load PDF Documents\n",
    "    for pdf in pdf_paths:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        documents.extend(loader.load())\n",
    "    \n",
    "    # Load Web Data\n",
    "    # web_loader = WebBaseLoader(web_links)\n",
    "    # documents.extend(web_loader.load())\n",
    "    \n",
    "    return documents\n",
    "\n",
    "pdf_files = ['Documents/Bill Gates Resume.pdf', 'Documents/Bill Gates - Wikipedia.pdf']\n",
    "\n",
    "\n",
    "# Combine all documents\n",
    "documents = load_documents(pdf_files) # , web_links)\n",
    "\n",
    "# Document Transformation\n",
    "# Split Text into Chunks for better embedding\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crate vector store for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mgmgk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings and store for retrieval\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "#model_name = 'sentence-transformers/all-MiniLM-L6-v2' # experiment with different models\n",
    "\n",
    "# Use Hugging Face embeddings instead of OpenAI\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "                   model_name=model_name,\n",
    "                   model_kwargs={\"device\": device})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vector locally\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents = split_documents,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "vector_path = 'vector-store'\n",
    "db_file_name = 'nlp_vector_store'\n",
    "\n",
    "vector_store.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'nlp' #default index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare retrievers\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading vector from local\n",
    "vector_path = 'vector-store'\n",
    "db_file_name = 'nlp_vector_store'\n",
    "\n",
    "vector_store = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp', #default index\n",
    "    allow_dangerous_deserialization=True  # required to load from pickle\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever is ready for query processing.\n"
     ]
    }
   ],
   "source": [
    "# Define retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "#retriever = vector_store.as_retriever()\n",
    "print(\"Retriever is ready for query processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgmgk\\AppData\\Local\\Temp\\ipykernel_15972\\4182072761.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents(\"What is your name\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='6428d544-e4e0-4dc4-b0ea-d1b4b1b7d87e', metadata={'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'creationdate': '2025-03-13T22:15:23+07:00', 'author': 'Kyi Tha', 'moddate': '2025-03-13T22:15:23+07:00', 'title': 'Microsoft Word - Bill Gates Resume.docx', 'source': 'Documents/Bill Gates Resume.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Bill Gates \\n \\nEmail: bill.gates@gatesfoundation.org \\nWebsite: www.gatesfoundation.org \\nLinkedIn: linkedin.com/in/billgates \\nTwitter: @BillGates \\n \\nFull Name  : William Henry Gates III \\nDate of Birth  : October 28, 1955 (age 69) \\nPlace of Birth  : Seattle, Washington, U.S. \\nEducation  : Harvard University (dropped out) \\nSpouse  : Melinda French \\n    (m. 1994; div. 2021) \\nChildren  : 3 \\nParents  :  Bill Gates Sr., Mary Maxwell \\n \\nProfessional Summary \\nVisionary entrepreneur, technologist, and philanthropist with a proven track record of \\nrevolutionizing the technology industry and addressing global challenges. Co-founder of \\nMicrosoft, the worldâ€™s leading software company, and co-chair of the Bill & Melinda \\nGates Foundation, one of the largest private charitable organizations. Recognized for \\ninnovation, leadership, and commitment to improving lives worldwide. \\n \\nKey Achievements \\n\\uf0b7 Co-founded Microsoft in 1975, transforming it into a global leader in software'),\n",
       " Document(id='3a9137b3-c2a2-4508-ba06-79095dfceee1', metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-14T13:18:50+00:00', 'moddate': '2025-03-14T20:20:55+07:00', 'title': 'Bill Gates - Wikipedia', 'source': 'Documents/Bill Gates - Wikipedia.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='\"Trey\" (i.e., three) because his father had the \"II\" suffix.[6][7] The family lived in the Sand Point\\narea of Seattle in a home that was damaged by a rare tornado when Gates was 7.[8]\\nWhen Gates was young his parents wanted him to pursue a career in law.[9] During his childhood,\\nhis family regularly attended a church of the Congregational Christian Churches, a Protestant\\nReformed denomination.[10][11][12]\\nGates was small for his age and was bullied as a child.[7] The family encouraged competition; one\\nvisitor reported that \"it didn\\'t matter whether it was hearts or pickleball or swimming to the dock;\\nthere was always a reward for winning and there was always a penalty for losing\".[13]\\nAt age 13, he enrolled in the private Lakeside prep school.[14][15] When he was in the eighth grade,\\nthe Mothers\\' Club at the school used proceeds from Lakeside School\\'s rummage sale to buy a\\nTeletype Model 33 ASR terminal and a block of computer time on a General Electric (GE)')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the retriever\n",
    "retriever.get_relevant_documents(\"What is your name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for Personal Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple QA prompt creation\n",
    "prompt_template = \"\"\"Answer the following question based solely on the provided context. \n",
    "If the answer is not present in the context, say 'I don't know.'\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RAG System\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df036da6b84543efa87698df6bcac5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff90e91edb64ec988f9c9d48d23fdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74220a53bfe14957828be409eaa9699c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253bfba7d8bd410f8f8464301b016604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511c8c7662c945deaf3faea37943ebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19630ebdee04451a1f3d0657f7b57dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93ca8e0dd484ae28901da9ec8170343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Define the retrieval chain\n",
    "# here are all the LLM models I am going to explore\n",
    "\n",
    "# llm = HuggingFacePipeline.from_model_id(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", task=\"text-generation\", device=0)\n",
    "\n",
    "# llm = HuggingFacePipeline.from_model_id(\"microsoft/phi-2\", task=\"text-generation\", device=0)\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\"gpt2-medium\", task=\"text-generation\", device=0, pipeline_kwargs={\"max_new_tokens\": 200} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Question Answering with RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type='stuff',\n",
    "    return_source_documents=True,  # crucial to keep answer concise\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Answer the following question based solely on the provided context. \n",
      "If the answer is not present in the context, say 'I don't know.'\n",
      "\n",
      "Context: \"Trey\" (i.e., three) because his father had the \"II\" suffix.[6][7] The family lived in the Sand Point\n",
      "area of Seattle in a home that was damaged by a rare tornado when Gates was 7.[8]\n",
      "When Gates was young his parents wanted him to pursue a career in law.[9] During his childhood,\n",
      "his family regularly attended a church of the Congregational Christian Churches, a Protestant\n",
      "Reformed denomination.[10][11][12]\n",
      "Gates was small for his age and was bullied as a child.[7] The family encouraged competition; one\n",
      "visitor reported that \"it didn't matter whether it was hearts or pickleball or swimming to the dock;\n",
      "there was always a reward for winning and there was always a penalty for losing\".[13]\n",
      "At age 13, he enrolled in the private Lakeside prep school.[14][15] When he was in the eighth grade,\n",
      "the Mothers' Club at the school used proceeds from Lakeside School's rummage sale to buy a\n",
      "Teletype Model 33 ASR terminal and a block of computer time on a General Electric (GE)\n",
      "\n",
      "Bill Gates \n",
      " \n",
      "Email: bill.gates@gatesfoundation.org \n",
      "Website: www.gatesfoundation.org \n",
      "LinkedIn: linkedin.com/in/billgates \n",
      "Twitter: @BillGates \n",
      " \n",
      "Full Name  : William Henry Gates III \n",
      "Date of Birth  : October 28, 1955 (age 69) \n",
      "Place of Birth  : Seattle, Washington, U.S. \n",
      "Education  : Harvard University (dropped out) \n",
      "Spouse  : Melinda French \n",
      "    (m. 1994; div. 2021) \n",
      "Children  : 3 \n",
      "Parents  :  Bill Gates Sr., Mary Maxwell \n",
      " \n",
      "Professional Summary \n",
      "Visionary entrepreneur, technologist, and philanthropist with a proven track record of \n",
      "revolutionizing the technology industry and addressing global challenges. Co-founder of \n",
      "Microsoft, the worldâ€™s leading software company, and co-chair of the Bill & Melinda \n",
      "Gates Foundation, one of the largest private charitable organizations. Recognized for \n",
      "innovation, leadership, and commitment to improving lives worldwide. \n",
      " \n",
      "Key Achievements \n",
      "ï‚· Co-founded Microsoft in 1975, transforming it into a global leader in software\n",
      "\n",
      "Question: What is your name?\n",
      "\n",
      "Answer: William Henry Gates Gates\n",
      "\n",
      "ï‚· Gestedechnology, the application of cutting-edge technologies to solving real-world problems while\n",
      "\n",
      "avoiding the \"waste\" of existing technologies of today.\n",
      "\n",
      "ï‚· Lead researcher of \n",
      "\n",
      "Project Ara, the high-tech, portable home computer for the world in\n",
      "\n",
      "the next decade, designed specifically to accommodate our world's unique needs.\n",
      "\n",
      "ï‚· Microsoft software was the first to develop universal applications for the world's\n",
      "\n",
      "internet of things devices, allowing Internet users from across the globe to seamlessly\n",
      "\n",
      "communicate on the Microsoft Worldwide Network, the world's leading social Ã‚ Ã‚ Ã‚ network\n",
      "\n",
      "ï‚· Founded Sun Microsystems - the world's leading research, development and marketing firm, providing\n",
      "\n",
      "research, software, hardware, services, marketing and investment at a global level\n",
      "\n",
      "ï‚· Created \"Microsoft,\" a new type of technology that harnesses\n"
     ]
    }
   ],
   "source": [
    "# Run single Query on the QA Chain\n",
    "query = \"What is your name?\"\n",
    "result = qa_chain.invoke({\"query\": query}) \n",
    "\n",
    "# Check Results\n",
    "print(\"Answer:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is your name?\n",
      "First Answer: William Henry Gates Gates\n",
      "Source Documents: ['Documents/Bill Gates - Wikipedia.pdf', 'Documents/Bill Gates Resume.pdf']\n"
     ]
    }
   ],
   "source": [
    "# extracting relevant first answer only\n",
    "match = re.search(r'Answer:\\s*(.+)', result[\"result\"])\n",
    "first_answer = match.group(1).strip() if match else \"No answer found.\"\n",
    "# Extract source documents\n",
    "source_docs = result.get(\"source_documents\", [])\n",
    "# Extract and print document names\n",
    "source_names = [doc.metadata.get(\"source\", \"Unknown source\") for doc in source_docs]\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"First Answer:\", first_answer)\n",
    "print(\"Source Documents:\", source_names)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating strings of questions and creating Q&A collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is your name?\n",
      "Answer: Bill Gates. Â  Bill is known worldwide for his contributions to the world-\n",
      "\n",
      "Question: How old are you?\n",
      "Answer: 79 years old\n",
      "\n",
      "Question: What is your highest level of education?\n",
      "Answer: University of California Santa Barbara University of Maryland (MAU) Harvard University, B.E., MS, in Mathematics; Oxford University, MBA/MA, MS; University of Miami, MA.\n",
      "\n",
      "Question: What major or field of study did you pursue during your education?\n",
      "Answer: None.\n",
      "\n",
      "Question: How many years of work experience do you have?\n",
      "Answer: One â€“ at a government agency that has no expertise in\n",
      "\n",
      "Question: What type of work or industry have you been involved in?\n",
      "Answer: None in particular.\n",
      "\n",
      "Question: Can you describe your current role or job responsibilities?\n",
      "Answer: During my current role I am the President and CEO (and co-founder and current CEO) of TechKiva, an\n",
      "\n",
      "Question: What are your core beliefs regarding the role of technology in shaping society?\n",
      "Answer: One of the core beliefs of that group is what is perhaps best said: When you\n",
      "\n",
      "Question: How do you think cultural values should influence technological advancements?\n",
      "Answer: Well, one way or another, they have the potential to be harmful to those who can identify them very well. (He said that at this point I should try to be\n",
      "\n",
      "Question: As a masterâ€™s student, what is the most challenging aspect of his studies so far?\n",
      "Answer: He was born in St. Louis in the '70â€²s but arrived in Cambridge\n",
      "\n",
      "Question: What specific research interests or academic goals does Kaung hope to achieve during your time as a masterâ€™s student?\n",
      "Answer: I am trying to understand how our culture is creating a bubble of privilege in which the majority of the population has become dependent on the handouts in the name of freedom, or\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    'What is your name?',   \n",
    "    'How old are you?',\n",
    "    'What is your highest level of education?',\n",
    "    'What major or field of study did you pursue during your education?',\n",
    "    'How many years of work experience do you have?',\n",
    "    'What type of work or industry have you been involved in?',\n",
    "    'Can you describe your current role or job responsibilities?',\n",
    "    'What are your core beliefs regarding the role of technology in shaping society?',\n",
    "    'How do you think cultural values should influence technological advancements?',\n",
    "    'As a masterâ€™s student, what is the most challenging aspect of his studies so far?',\n",
    "    'What specific research interests or academic goals does Kaung hope to achieve during your time as a masterâ€™s student?'\n",
    "    ]\n",
    "answers = []\n",
    "for query in questions:\n",
    "    result = qa_chain.invoke({\"query\": query}) \n",
    "    match = re.search(r'Answer:\\s*(.+)', result[\"result\"])\n",
    "    first_answer = match.group(1).strip() if match else \"No answer found.\"\n",
    "    answers.append({'question': query, 'answer': first_answer})\n",
    "\n",
    "# Printing answers in a more readable format\n",
    "for entry in answers:\n",
    "    print(f\"Question: {entry['question']}\\nAnswer: {entry['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers saved to 'answers_gpt2.json'\n"
     ]
    }
   ],
   "source": [
    "# save to json file\n",
    "import json\n",
    "with open('answers_gpt2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(answers, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Answers saved to 'answers_gpt2.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
