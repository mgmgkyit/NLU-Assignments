{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation + Transformer\n",
    "\n",
    "English-Myanmar Translation using Transformers\n",
    "\n",
    "Training for Multiplicative Attention\n",
    "\n",
    "Maung Maung Kyi Tha : st125214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install numpy==1.26.4\\n!pip3 install torch==2.2.0\\n!pip3 install torchdata\\n!pip3 install torchtext==0.16.2\\n!pip3 install portalocker\\n!pip3 install datasets\\n!pip3 install spacy\\n!pip3 install matplotlib\\n!python3 -m spacy download en_core_web_sm\\n!pip3 install pyidaungsu\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# to be run only first time, if you haven't installed libraries\n",
    "'''\n",
    "!pip install numpy==1.26.4\n",
    "!pip3 install torch==2.2.0\n",
    "!pip3 install torchdata\n",
    "!pip3 install torchtext==0.16.2\n",
    "!pip3 install portalocker\n",
    "!pip3 install datasets\n",
    "!pip3 install spacy\n",
    "!pip3 install matplotlib\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!pip3 install pyidaungsu\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Loading libraries\n",
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random, math, time\n",
    "import numpy\n",
    "\n",
    "# setting device to GPU cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Seet my seed\n",
    "SEED = 69\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Making sure we get the same results on each run\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Disable user warnings for neater output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using GPU device : NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "My torch library version : 2.2.0+cu118\n",
      "My torchtext library version : 0.16.2+cpu\n"
     ]
    }
   ],
   "source": [
    "# What is my device, and cuda versions\n",
    "print(f\"I am using GPU device : {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"My torch library version : {torch.__version__}\")\n",
    "print(f\"My torchtext library version : {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  2 20:25:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.14                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   41C    P8              4W /  140W |    5737MiB /   6141MiB |      7%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6596    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      7000    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      7792    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      8944    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      9644    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      9660    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     10640    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     11232    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     11332    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11424    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12860    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13072    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14780    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18044    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     19776    C+G   ...n\\132.0.2957.127\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19868    C+G   ...2.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     21428    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     22184      C   ...0_x64__qbz5n2kfra8p0\\python3.12.exe      N/A      |\n",
      "|    0   N/A  N/A     23840    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     23864    C+G   ...5.9.2.0_x64__htrsf667h5kn2\\AWCC.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# only for colab pro\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset\n",
    "\n",
    "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English-myanmar parallel dataset from torchtext.datasets \n",
    "import torchtext, datasets\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TRG_LANGUAGE = 'mm'\n",
    "\n",
    "# I've experimented with two different english-myanmar parallel datasets here\n",
    "\n",
    "# Import parallel dataset by Aung Kaung Htet\n",
    "dataset = datasets.load_dataset('akhtet/myanmar-xnli')\n",
    "\n",
    "# Import parallel dataset uploaded from Christan bible translation\n",
    "#dataset = datasets.load_dataset('st125338/en_my_nlp_a3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 5010\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking structure of parallel dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing for Christan bible translation\n",
    "# train = [(row['en'], row['my']) for row in dataset['train']]\n",
    "# val = [(row['en'], row['my']) for row in dataset['validation']]\n",
    "# test = [(row['en'], row['my']) for row in dataset['test']]\n",
    "\n",
    "# Processing for parallel dataset by Aung Kaung Htet\n",
    "# since this dataset has two separate parallel sets, we will choose second set\n",
    "train = [(row['sentence2_en'], row['sentence2_my']) for row in dataset['train']]\n",
    "val = [(row['sentence2_en'], row['sentence2_my']) for row in dataset['validation']]\n",
    "test =  [(row['sentence2_en'], row['sentence2_my']) for row in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Product and geography are what make cream skimming work. ', 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။'), ('You lose the things to the following level if the people recall.', 'လူတွေပြန်ခေါ်ရင် အောက်ပါအဆင့်အထိ ဆုံးရှုံးသွားမယ်။'), ('A member of my team will execute your orders with immense precision.', 'ကျွန်ုပ်၏အဖွဲ့သားတစ်ဦးသည် သင်၏အမိန့်စာများကို အလွန်တိကျစွာ ဆောင်ရွက်ပေးပါမည်။'), ('This information belongs to them.', 'ဒီအချက်အလက်က သူတို့ပိုင်တယ်။'), ('The tennis shoes have a range of prices.', 'တင်းနစ်ဖိနပ်များသည် ဈေးနှုန်းအမျိုးမျိုးရှိသည်။'), (\"I'm upset that my walkman broke and now I have to turn the stereo up really loud.\", 'ကျွန်တော့်ရဲ့ လမ်းလျှောက်သမား ပြတ်သွားလို့ စိတ်မကောင်းဖြစ်ပြီး အခု စတီရီယိုကို တကယ် အသံကျယ်အောင် ပြန်ဖွင့်ရမှာ ဖြစ်ပါတယ်။'), ('Most of the Christian mosaics were destroyed by Muslims.  ', 'ခရစ်ယာန် ဗလီစာ အများစုကို မူဆလင်များက ဖျက်ဆီးခဲ့သည်။'), (\"Slate had an opinion on Jackson's findings.\", 'Slate သည် Jackson ၏တွေ့ရှိချက်အပေါ်အမြင်တစ်ခုရှိသည်။'), ('Heterosexuals.', 'ကဿာမိ။'), ('Place des Vosges is constructed entirely of gray marble.', 'Place des Vosges ကို မီးခိုးရောင် စကျင်ကျောက်ဖြင့် လုံး၀ တည်ဆောက်ထားသည်။')]\n",
      "[('He called his mom as soon as the school bus dropped him off.', 'ကျောင်းကားက သူ့ကို ချပေးပြီးပြီးချင်း သူက သူ့အမေကို ခေါ်ခဲ့တယ်။'), (\"He didn't say a word.\", 'သူ စကားတစ်လုံးမပြောခဲ့ဘူး။'), ('He told his mom he had gotten home.', 'သူ အိမ်ပြန်ရောက်ပြီလို့ သူ့အမေကို ပြောခဲ့တယ်။'), ('I have never been to Washington so when I was assigned there I got lost trying to find the place.', 'ဝါရှင်တန်ကို ကျွန်တော် တစ်ခါမှမရောက်ဖူးတာကြောင့် ကျွန်တော့်ကို အဲ့ဒီကို တာဝန်ပေးခံရ သောအခါ နေရာရှာရင်းနဲ့ လမ်းပျောက်ခဲ့တယ်။'), ('I knew exactly what I needed to do as I marched to Washington.', 'ဝါရှင်တန်ကို ငါချီတက်ခဲ့တာနဲ့ ငါ ဘာလုပ်ဖို့ လိုခဲ့လိုဆိုတာကို ငါအတိအကျ သိခဲ့တယ်။'), ('I was not quite certain what I was going to do so I went to Washington where I was assigned to report.', 'ငါ ဘာလုပ်ရမယ်ဆိုတာ ငါတော်တော် မသေချာခဲ့ဘူး ဒါကြောင့် ငါ တာဝန်ပေးခံရတဲ့ ဝါရှင်တန်ကို သတင်းပို့ဖို့ သွားခဲ့တယ်။'), ('He was the first to be invited and enjoyed the experience.', 'သူဟာ ပထမဆုံးဖိတ်ခံခဲ့ရပြီး အတွေ့အကြုံကို ခံစားပျော်ရွှင်ခဲ့တယ်။'), (\"He wasn't allowed to attend.\", 'သူ တက်ရောက်ခွင့်မရခဲ့ဘူး။'), (\"He wasn't allowed to go to the museum's opening.\", 'သူ့ကို ပြတိုက်ဖွင့်ပွဲ သွားဖို့ ခွင့်မပြုခဲ့ဘူး။'), ('After I said yes, it ended.', 'ငါ အင်း လို့ ပြောပြီးနောက် ၊ အဲ့ဒါ ပြီးသွားခဲ့တယ်။')]\n",
      "[('I havent spoken to him again.', 'ငါ သူ့ကို စကား ထပ်မပြောဖြစ်ဘူး။'), ('I was so upset that I just started talking to him again.', 'ငါ အရမ်းစိတ်မကောင်းဖြစ်လို့ သူကို တဖန် စကားစပြောရုံပါပဲ။'), ('We had a great talk.', 'ငါတို့ စကားကောင်းခဲ့တယ်။'), ('I was not aware that I was not the only person to be at the field that day.', 'အဲ့ဒီနေ့က ကွင်းထဲမှာ ရှိတဲ့သူက ကျွန်တော်တစ်ယောက်ထဲပဲမဟုတ်လို့ ကျွန်တော် သတိမထားမိခဲ့ဘူး။'), ('I was under the impression that I was the only one with that number at the AFFC Air Force Career field.', 'ကျွန်တော် က အေအက်ဖ်အက်ဖ်စီ လေတပ် အသက်မွေးဝမ်းကြောင်း လုပ်ငန်း မှာ အဲလို နံပါတ်နဲ့ တစ်ယောက်တည်းသောသူ လို့ ကျွန်တော် ထင်မြင်ခဲ့တယ်။'), ('We all were given the same exact number no matter what privileges we were promised to be granted, it was all a lie.', 'အခွင့်ထူးတွေ ခွင့်ပြုပေးဖို့ ကျွန်တော်တို့ကို ကတိပေးထားခဲ့ပေမယ့် ကျွန်တော်တို့အားလုံး အတိအကျ တူညီတဲ့ အရေအတွက်တွေ ပေးခြင်းခံရတယ်၊ ဒါတွေ အားလုံးက အလိမ်အညာပဲ။'), ('I was never told anything about meeting anyone.', 'တယောက်ယောက်နဲ့ တွေ့ဖို့အကြောင်း ငါ ဘယ်တုန်းကမှ အပြောမခံခဲ့ရဘူး။'), ('I was told a guy would be called in for me to meet.', 'ငါ့တွေ့ဖို့ ယောက်ျားလေးတစ်ယောက်ကို ခေါ်သွင်း လိမ့်မယ်လို့ ငါ့ကိုပြောခဲ့တယ်။'), ('The guy showed up a bit late.', 'အဲ့ဒီ ယောက်ျားလေးဟာ အနည်းငယ် နောက်ကျပြီးမှ ရောက်လာခဲ့တယ်။'), ('I want to tell you everything I know about that!', 'အဲ့ဒါနဲ့ ပတ်သက်ပြီး ငါ သိသမျှကို မင်းကို ပြောပြချင်တယ်!')]\n"
     ]
    }
   ],
   "source": [
    "#so this is a datapipe object; very similar to pytorch dataset version 2 which is better\n",
    "print(train[0:10])\n",
    "print(val[0:10])\n",
    "print(test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Product and geography are what make cream skimming work. ',\n",
       " 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking What does it looks like\n",
    "sample = next(iter(train))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of training dataset\n",
    "train_size_all = len(list(iter(train)))\n",
    "train_size_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_part1 : 137445\n"
     ]
    }
   ],
   "source": [
    "# Since The size is too much (400,000 lines), I will reduce the train size into 35% of original,\n",
    "# and then split again into train, val and test datasets\n",
    "# I will not use random split, but just split by index to make the train set consistent between the three model experimentations\n",
    "\n",
    "# Define the split ratio\n",
    "split_ratio = 0.35\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(train) * split_ratio)\n",
    "\n",
    "# Divide the train dataset into two parts\n",
    "train_part1 = train[:split_index]\n",
    "print(f'size of train_part1 : {len(train_part1)}')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "generator = torch.Generator().manual_seed(69)\n",
    "\n",
    "# Now splitting again\n",
    "train_size_all = len(list(iter(train_part1)))\n",
    "train_size = int(0.7 * train_size_all)\n",
    "val_size = int(0.2 * train_size_all)\n",
    "test_size = train_size_all - (train_size + val_size)  # Ensure all data is included\n",
    "\n",
    "# Perform the split again for final train, val and test\n",
    "train, val, test = torch.utils.data.random_split(train_part1, [train_size, val_size, test_size], generator)\n",
    "\n",
    "# after this, newly sized train, val and test will be used for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final training\n",
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final validation\n",
    "val_size = len(list(iter(val)))\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final test\n",
    "test_size = len(list(iter(test)))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n",
    "\n",
    "**Note**: the models must first be downloaded using the following on the command line: \n",
    "```\n",
    "python3 -m spacy download en_core_web_sm\n",
    "```\n",
    "For myanmar tokenizing, we will use a custom tokenizer with PyICU\n",
    "\n",
    "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myanmar word tokenizer with PyICU\n",
    "from icu import BreakIterator, Locale\n",
    "\n",
    "def pyicu_tokenizer(sentence):\n",
    "    bi = BreakIterator.createWordInstance(Locale(TRG_LANGUAGE))\n",
    "    bi.setText(sentence)\n",
    "    tokens = []\n",
    "    start = bi.first()\n",
    "    for end in bi:\n",
    "        token = sentence[start:end].strip()  # remove leading/trailing spaces\n",
    "        if token:  # only add non-empty tokens\n",
    "            tokens.append(token)\n",
    "        start = end\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': functools.partial(<function _spacy_tokenize at 0x000001E296F24040>, spacy=<spacy.lang.en.English object at 0x000001E2D76DFA40>),\n",
       " 'mm': <function __main__.pyicu_tokenizer(sentence)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining english and myanmar word tokenizers\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TRG_LANGUAGE] = pyicu_tokenizer\n",
    "token_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Product and geography are what make cream skimming work. \n",
      "Tokenization:  ['Product', 'and', 'geography', 'are', 'what', 'make', 'cream', 'skimming', 'work', '.'] ['ထုတ်ကုန်နှင့်', 'ပထဝီဝင်အနေအထားသည်', 'ခရင်မ်', 'skimming', 'ကို', 'အလုပ်ဖြစ်စေသည်။']\n",
      "('Product and geography are what make cream skimming work. ', 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။')\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "print(\"Sentence: \", sample[0])\n",
    "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]), token_transform[SRC_LANGUAGE](sample[1]))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text to integers (Numericalization)\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
    "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 10, 9, 0, 9]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see some example\n",
    "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marriage'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
    "\n",
    "#print 1816, for example\n",
    "mapping[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try unknown vocab\n",
    "mapping[0]\n",
    "#they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24533"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n",
    "\n",
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# reduce batch size to avoid GPU memory error\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# reduce batch size to avoid GPU memory error\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, mm in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([32, 24])\n",
      "Myanmar shape:  torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
    "print(\"Myanmar shape: \", mm.shape)   # (batch_size, seq len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model\n",
    "\n",
    "<img src=\"../figures/transformer-encoder.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        _src    = self.feedforward(src)\n",
    "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                           for _ in range(n_layers)])\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len    = src.shape[1]\n",
    "        \n",
    "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, src_len]\n",
    "        \n",
    "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutli Head Attention Layer\n",
    "\n",
    "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative Attention (Luong Dot-Product Attention)\n",
    "\n",
    "Formula (Simplified Dot-Product version):\n",
    "\n",
    "<img src = \"figures/multiplicative formula.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim  = hid_dim\n",
    "        self.n_heads  = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        # Multiplicative Attention : Learnable Weight\n",
    "        self.w = nn.Linear(self.head_dim, self.head_dim)\n",
    "        \n",
    "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "                \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        #src, src, src, src_mask\n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        #Q=K=V: [batch_size, src len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        #Q = [batch_size, n heads, query len, head_dim]\n",
    "        \n",
    "        # Multiplicative Attention : Scale\n",
    "        K_ = self.w(K)\n",
    "\n",
    "        #energy = torch.matmul(Q, K_.transpose(1, 2)) / self.scale\n",
    "        energy = torch.matmul(Q, K_.transpose(-2, -1)) / self.scale\n",
    "        \n",
    "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
    "        #energy = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        #for making attention to padding to 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        #attention = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
    "        #x = [batch_size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
    "        #x = [batch_size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        return x, attention\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [batch size, src len, hid dim]\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder Layer\n",
    "\n",
    "<img src = \"../figures/transformer-decoder.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        #attention = [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        _trg = self.feedforward(trg)\n",
    "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
    "                 pf_dim, dropout, device,max_length = 100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                            for _ in range(n_layers)])\n",
    "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len    = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, trg len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            \n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        #attention: [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        #output = [batch_size, trg len, output_dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together (become Seq2Seq!)\n",
    "\n",
    "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 1\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
    "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(24533, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(14410, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=14410, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
    "hid_dim = 256\n",
    "enc_layers = 3\n",
    "dec_layers = 3\n",
    "enc_heads = 8\n",
    "dec_heads = 8\n",
    "enc_pf_dim = 512\n",
    "dec_pf_dim = 512\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX\n",
    "\n",
    "enc = Encoder(input_dim, \n",
    "              hid_dim, \n",
    "              enc_layers, \n",
    "              enc_heads, \n",
    "              enc_pf_dim, \n",
    "              enc_dropout, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(output_dim, \n",
    "              hid_dim, \n",
    "              dec_layers, \n",
    "              dec_heads, \n",
    "              dec_pf_dim, \n",
    "              enc_dropout, \n",
    "              device)\n",
    "\n",
    "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6280448\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3688960\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3688960\n",
      " 14410\n",
      "______\n",
      "17687146\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "# increase learning rate due to GPU compute limitations\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
    "\n",
    "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
    "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
    "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_len, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg    = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg    = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_len, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n",
    "\n",
    "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
    "\n",
    "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))\n",
    "test_loader_length  = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 26s\n",
      "\tTrain Loss: 4.413 | Train PPL:  82.507\n",
      "\t Val. Loss: 3.860 |  Val. PPL:  47.477\n",
      "Epoch: 02 | Time: 2m 24s\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.574\n",
      "\t Val. Loss: 3.667 |  Val. PPL:  39.154\n",
      "Epoch: 03 | Time: 2m 23s\n",
      "\tTrain Loss: 3.650 | Train PPL:  38.460\n",
      "\t Val. Loss: 3.636 |  Val. PPL:  37.943\n",
      "Epoch: 04 | Time: 2m 25s\n",
      "\tTrain Loss: 3.556 | Train PPL:  35.024\n",
      "\t Val. Loss: 3.614 |  Val. PPL:  37.109\n",
      "Epoch: 05 | Time: 2m 23s\n",
      "\tTrain Loss: 3.473 | Train PPL:  32.245\n",
      "\t Val. Loss: 3.574 |  Val. PPL:  35.673\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs = 5\n",
    "clip       = 1\n",
    "\n",
    "# name of model - for general attention\n",
    "save_path = f'models/{model.__class__.__name__}_multiplicative.pt'\n",
    "model_name = f'{model.__class__.__name__}_multiplicative.pt'\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "    \n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    #lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAEmCAYAAADiGtAlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGXUlEQVR4nO3deVxU9f7H8dcwMGzDKgoKKG4oIqCClViZiblFapaV3KxfWrfSm1ZWWr9Ss0SzW7aY12v74s/KrUXNrbQ0TQQRVNxZE8WNTWSbOb8/BkeRRUDgDPB5Ph7n0eXMd2Y+HOfOm+/3nPP9ahRFURBCCCFEpazULkAIIYSwZBKUQgghRDUkKIUQQohqSFAKIYQQ1ZCgFEIIIaohQSmEEEJUQ4JSCCGEqIYEpRBCCFENa7ULaGxGo5GTJ0/i5OSERqNRuxwhhBAqURSFvLw82rVrh5VV1f3GFheUJ0+exNfXV+0yhBBCWIj09HR8fHyqfLzFBaWTkxNgOjDOzs4qVyOEEEItubm5+Pr6mnOhKi0uKC8Ptzo7O0tQCiGEuO5pOLmYRwghhKiGBKUQQghRDQlKIYQQohot7hylEELUlKIolJaWYjAY1C5F1IFWq8Xa2vqGbwWUoBRCiEoUFxeTmZlJQUGB2qWIG+Dg4EDbtm3R6XR1fg0JyjoyGhUulRhwtJVDKERzYzQaSU5ORqvV0q5dO3Q6nUxQ0sQoikJxcTFnzpwhOTmZrl27VjupQHUs5lt+3rx5zJgxgylTprBw4cLrtl++fDkPPfQQI0eOZM2aNQ1e39VOnMnnpZUJtHGyY1FUn0Z9byFEwysuLsZoNOLr64uDg4Pa5Yg6sre3x8bGhtTUVIqLi7Gzs6vT61jExTwxMTEsWbKE4ODgGrVPSUlh2rRp3HbbbQ1cWeUulRiIS8tmbWImmw6eVqUGIUTDq2sPRFiO+vg3VP1TkJ+fT1RUFEuXLsXNze267Q0GA1FRUcyePZtOnTo1QoUVBbZz4fHbTO/96pr95BWWqFKHEEKIhqd6UE6aNIkRI0YQERFRo/avv/46bdq0YcKECTVqX1RURG5ubrmtPkyN6EqHVg6cyi3krV8O18trCiGEsDyqBuXy5cuJi4sjOjq6Ru23b9/OJ598wtKlS2v8HtHR0bi4uJi3+poQ3c5GS/S9QQB8tSuVPSnn6+V1hRDCkvj5+dXoupGGfg01qRaU6enpTJkyhW+++aZGJ1jz8vJ4+OGHWbp0KR4eHjV+nxkzZpCTk2Pe0tPTb6TscsI7e/BAmCl4X1qZQFGp3GslhFDXHXfcwdSpU+vt9WJiYnjiiSfq7fWaItWueo2NjSUrK4s+fa5cNWowGPj999/58MMPKSoqQqvVmh87fvw4KSkpREZGmvcZjUYArK2tOXz4MJ07d67wPra2ttja2jbY7/Hy8AC2HMri+JmLLPrtOM8N9m+w9xJCiPqgKAoGgwFr6+tHQOvWrRuhIsumWo9y0KBBJCYmEh8fb97CwsKIiooiPj6+XEgCdO/evUL7e+65h4EDBxIfH6/aGpMuDja8PjIQgMVbj3HkdJ4qdQghGpaiKBQUl6qyKYpSoxofffRRtm3bxnvvvYdGo0Gj0ZCSksLWrVvRaDSsX7+e0NBQbG1t2b59O8ePH2fkyJF4enqi1+vp27cvmzdvLvea1w6bajQaPv74Y0aPHo2DgwNdu3blxx9/rNWxTEtLY+TIkej1epydnRk7diynT1+5g2Dfvn0MHDgQJycnnJ2dCQ0NZc+ePQCkpqYSGRmJm5sbjo6OBAYGsm7dulq9f22p1qN0cnKiZ8+e5fY5OjrSqlUr8/7x48fj7e1NdHQ0dnZ2Fdq7uroCVNjf2Ib19CIiwJPNSad5aWUCK54MR2slNycL0ZxcKjHQ47UNqrz3wdeH4KC7/tf1e++9x5EjR+jZsyevv/46YOoRpqSkADB9+nTefvttOnXqhJubG+np6QwfPpw333wTW1tbvvzySyIjIzl8+DDt27ev8n1mz57NW2+9xYIFC/jggw+IiooiNTUVd3f369ZoNBrNIblt2zZKS0uZNGkSDzzwAFu3bgUgKiqK3r17s3jxYrRaLfHx8djY2ACmC0CLi4v5/fffcXR05ODBg+j1+uu+742wmAkHKpOWltYk7mPSaDTMGRXIrhPn2JuWzde7Unkk3E/tsoQQLYyLiws6nQ4HBwe8vLwqPP76668zePBg88/u7u6EhISYf54zZw6rV6/mxx9/ZPLkyVW+z6OPPspDDz0EwNy5c3n//ffZvXs3Q4cOvW6NW7ZsITExkeTkZPNI4JdffklgYCAxMTH07duXtLQ0XnjhBbp37w5A165dzc9PS0tjzJgxBAWZLqZsjNsELSooL/81UdXP1/r8888brJbaautiz0vDuvPqmv289cshInp44u1qr3ZZQoh6Ym+j5eDrQ1R77/oQFhZW7uf8/HxmzZrF2rVryczMpLS0lEuXLpGWllbt61w9OYyjoyPOzs5kZWXVqIakpCR8fX3LnS7r0aMHrq6uJCUl0bdvX5577jkmTpzIV199RUREBPfff7/5GpRnnnmGp556io0bNxIREcGYMWNqPFlNXVl+d60JibqpPWEd3LhYbODVNftrfF5BCGH5NBoNDjprVbb6mmfW0dGx3M/Tpk1j9erVzJ07lz/++IP4+HiCgoIoLi6u9nUuD4NefWwuX1xZH2bNmsWBAwcYMWIEv/76Kz169GD16tUATJw4kRMnTvDwww+TmJhIWFgYH3zwQb29d2UkKOuRlZWGeWOC0Gmt+PVQFj8nZKpdkhCihdHpdDVeFmzHjh08+uijjB49mqCgILy8vMznMxtKQEAA6enp5W7VO3jwINnZ2fTo0cO8z9/fn2effZaNGzdy77338tlnn5kf8/X15cknn2TVqlU8//zztbq3vi4kKOtZlzZOTBrYBYBZPx7gwsXq/zITQoj65Ofnx19//UVKSgpnz56ttqfXtWtXVq1aRXx8PPv27WPcuHH12jOsTEREBEFBQURFRREXF8fu3bsZP348AwYMICwsjEuXLjF58mS2bt1KamoqO3bsICYmhoCAAACmTp3Khg0bSE5OJi4ujt9++838WEORoGwAT93RGX9PPecuFvPmuiS1yxFCtCDTpk1Dq9XSo0cPWrduXe35xnfeeQc3NzfCw8OJjIxkyJAh5e5tbwgajYYffvgBNzc3br/9diIiIujUqRPffvstYFps+dy5c4wfPx5/f3/Gjh3LsGHDmD17NmC6337SpEkEBAQwdOhQ/P39+eijjxq2ZqWFnUjLzc3FxcWFnJwcnJ2dG+x9YlMvcN9//kRR4OsJN3Nr15rPJiSEUFdhYSHJycl07NixzkszCctQ3b9lTfNAepQNJLSDG4/08wNgxuoELhXL9HZCCNEUSVA2oGlDutHOxY7085d4d/MRtcsRQghRBxKUDUhva80bo02zBn38xwn2/52jckVCCCFqS4Kygd3Z3ZPIkHYYFXhxRQIlhoa9okwIIUT9kqBsBDMje+DqYMPBzFw+2Z6sdjlCCCFqQYKyEXjobfnfEaYbad/ddISUsxdVrkgIIURNSVA2kjF9vLm1iwdFpUZeXp0o09sJIUQTIUHZSDQaDXNHB2FnY8Wfx8/xfWyG2iUJIYSoAQnKRtS+lQPPDfYH4M21SWTlFapckRBCVFTZYs1r1qypsn1KSgoajYb4+Pgav2ZTIkHZyB7r35Ge3s7kXCph9k8H1S5HCCGuKzMzk2HDhqldhmokKBuZtdaKefcGo7XSsDYhk00HT6tdkhBCVMvLywtbW1u1y1CNBKUKenq78PhtplW5X12zn7zCEpUrEkI0B//9739p165dhRVARo4cyWOPPQbA8ePHGTlyJJ6enuj1evr27cvmzZurfd1rh153795N7969sbOzIywsjL1799a61rS0NEaOHIler8fZ2ZmxY8dy+vSVjsO+ffsYOHAgTk5OODs7Exoayp49ewBITU0lMjISNzc3HB0dCQwMZN26dbWuoaYkKFUyNaIrHVo5cCq3kLd+Oax2OUKI61EUKL6ozlbDq+Tvv/9+zp07x2+//Wbed/78eX755ReioqIAyM/PZ/jw4WzZsoW9e/cydOhQIiMjq11l5Gr5+fncfffd9OjRg9jYWGbNmsW0adNqdSiNRiMjR47k/PnzbNu2jU2bNnHixAkeeOABc5uoqCh8fHyIiYkhNjaW6dOnmxeMnjRpEkVFRfz+++8kJiYyf/589Hp9rWqoDesGe2VRLTsbLdGjgxj38V98/VcqI3u1I8zPXe2yhBBVKSmAue3Uee+XT4LO8brN3NzcGDZsGMuWLWPQoEEArFixAg8PDwYOHAhASEgIISEh5ufMmTOH1atX8+OPPzJ58uTrvseyZcswGo188skn2NnZERgYSEZGBk899VSNf50tW7aQmJhIcnIyvr6+AHz55ZcEBgYSExND3759SUtL44UXXqB79+6Aae3My9LS0hgzZgxBQUEAdOrUqcbvXRfSo1RReBcPxob5oCgwfVUiRaWywogQ4sZERUWxcuVKioqKAPjmm2948MEHsbIyfd3n5+czbdo0AgICcHV1Ra/Xk5SUVOMeZVJSEsHBweWWrOrXr1+takxKSsLX19cckgA9evTA1dWVpCTTGr7PPfccEydOJCIignnz5nH8+HFz22eeeYY33niD/v37M3PmTBISEmr1/rUlPUqVvTw8gF8PneFYVj4f/XacZ8tuHxFCWBgbB1PPTq33rqHIyEgURWHt2rX07duXP/74g3fffdf8+LRp09i0aRNvv/02Xbp0wd7envvuu4/i4uKGqLzOZs2axbhx41i7di3r169n5syZLF++nNGjRzNx4kSGDBnC2rVr2bhxI9HR0fz73//mX//6V4PUIj1Klbk66Jh9TyAAH209xpHTeSpXJISolEZjGv5UY9NoalymnZ0d9957L9988w3/93//R7du3ejTp4/58R07dvDoo48yevRogoKC8PLyIiUlpcavHxAQQEJCAoWFV+4D37VrV42ff/k10tPTSU9PN+87ePAg2dnZ9OjRw7zP39+fZ599lo0bN3Lvvffy2WefmR/z9fXlySefZNWqVTz//PMsXbq0VjXUhgSlBRge5EVEgCclBoXpKxMwGmV6OyFE3UVFRbF27Vo+/fRT80U8l3Xt2pVVq1YRHx/Pvn37GDduXIWrZKszbtw4NBoNjz/+OAcPHmTdunW8/fbbtaovIiKCoKAgoqKiiIuLY/fu3YwfP54BAwYQFhbGpUuXmDx5Mlu3biU1NZUdO3YQExNDQEAAAFOnTmXDhg0kJycTFxfHb7/9Zn6sIUhQWgCNRsOcUYHoba2JS8vm679S1S5JCNGE3Xnnnbi7u3P48GHGjRtX7rF33nkHNzc3wsPDiYyMZMiQIeV6nNej1+v56aefSExMpHfv3rzyyivMnz+/VvVpNBp++OEH3NzcuP3224mIiKBTp058++23AGi1Ws6dO8f48ePx9/dn7NixDBs2jNmzZwNgMBiYNGkSAQEBDB06FH9/fz766KNa1VCrepUWNjt3bm4uLi4u5OTk4OzsrHY55Xy1M4VXfziAo07LpucG0M7VXu2ShGiRCgsLSU5OpmPHjuUuWhFNT3X/ljXNA+lRWpComzsQ2sGNi8UGXl2zX1YYEUIICyBBaUGsrDTMuzcIndaKLYey+DkhU+2ShBCixZOgtDBdPZ2YNLALALN/OkB2gWVdsi2EEC2NBKUFeuqOzvh76jmbX8yba5PULkcIIVo0CUoLpLO2IvreYDQa+D42g+1Hz6pdkhBCtFgSlBYqtIMb42/pAMDLqxO5VCzT2wnR2OSCuqavPv4NJSgt2AtDu9PWxY608wUs3HxE7XKEaDEur1JRUFCgciXiRl3+N7z8b1oXMterBdPbWvPGqJ5M+GIPS/84QWRIO3p6u6hdlhDNnlarxdXVlaysLAAcHBzQ1GIaOaE+RVEoKCggKysLV1dXtFptnV9LgtLCDQrwJDKkHT/tO8lLKxP4YVJ/rLUyECBEQ/Py8gIwh6VomlxdXc3/lnVlMUE5b948ZsyYwZQpU1i4cGGlbZYuXcqXX37J/v37AQgNDWXu3LncdNNNjVhp45sZ2YM/jp7hwMlcPtmezD8HdFa7JCGaPY1GQ9u2bWnTpg0lJSVqlyPqwMbG5oZ6kpdZRFDGxMSwZMkSgoODq223detWHnroIcLDw7Gzs2P+/PncddddHDhwAG9v70aqtvF56G15ZXgAL6xI4J1NRxgS6IWfx/UXcRVC3DitVlsvX7ai6VJ9DC8/P5+oqCiWLl2Km5tbtW2/+eYbnn76aXr16kX37t35+OOPMRqNbNmypZGqVc99oT7079KKolIjL69OlKvxhBCikagelJMmTWLEiBFERETU+rkFBQWUlJTg7u5eZZuioiJyc3PLbU2RRqNh7ugg7Gys+PP4Ob6PzVC7JCGEaBFUDcrly5cTFxdHdHR0nZ7/0ksv0a5du2pDNjo6GhcXF/Pm6+tb13JV16GVI88N9gfgzbVJnMkrUrkiIYRo/lQLyvT0dKZMmcI333xTp2Vs5s2bx/Lly1m9enW1z58xYwY5OTnm7eoVtZuix/p3pKe3MzmXSpj90wG1yxFCiGZPtfUo16xZw+jRo8udJDcYDGg0GqysrCgqKqryBPrbb7/NG2+8webNmwkLC6vV+1ryepQ1tf/vHEYu2oHBqPDx+DAieniqXZIQQjQ5Fr8e5aBBg0hMTCQ+Pt68hYWFERUVRXx8fJUh+dZbbzFnzhx++eWXWodkc9HT24WJt3UE4NUf9pNXKJeuCyFEQ1Ht9hAnJyd69uxZbp+joyOtWrUy7x8/fjze3t7mc5jz58/ntddeY9myZfj5+XHq1CkA9Ho9er2+cX8BlU0d5M8v+0+Req6ABRsO8/rIntd/khBCiFpT/arX6qSlpZGZeWXx4sWLF1NcXMx9991H27Ztzdvbb7+tYpXqsNdpiR4dBMBXu1LZk3Je5YqEEKJ5Uu0cpVqawznKq724Yh/f7cmgSxs9a5+5FVtruTFaCCFqwuLPUYr68fLwADz0Oo5l5bN463G1yxFCiGZHgrKJc3XQMeueQAAW/XaMo6fzVK5ICCGaFwnKZmBEUFsiAtpQYlB4aWUCRmOLGk0XQogGJUHZDGg0GuaM6one1pq4tGy+/itV7ZKEEKLZkKBsJtq62PPS0G4AzF9/iJPZl1SuSAghmgcJymYk6uYOhHZw42KxgVfX7JcVRoQQoh5IUDYjVlYa5t0bhI1Ww5ZDWaxNzLz+k4QQQlRLgrKZ6erpxKSBXQCY9eMBsguKVa5ICCGaNgnKZuipOzrTtY2es/nFvLk2Se1yhBCiSZOgbIZsrbXMGxOMRgPfx2aw49hZtUsSQogmS4KymQrt4Mb4WzoA8PLqRC4VG1SuSAghmiYJymbshaHdaetiR+q5AhZuOaJ2OUII0SRJUDZjeltr3hhlWn7r4z+S2f93jsoVCSFE0yNB2cwNCvDk7uC2GIym6e1KDUa1SxJCiCZFgrIFmBkZiIu9DQdO5vLJ9mS1yxFCiCZFgrIFaO1ky/+OCADgnU1HSD13UeWKhBCi6ZCgbCHuC/Whf5dWFJUaeXl1okxvJ4QQNSRB2UJoNBrmjg7CzsaKHcfOsSI2Q+2ShBCiSZCgbEE6tHLk2Qh/AN5Ym8SZvCKVKxJCCMsnQdnCTLi1I4HtnMm5VMLsnw6oXY4QQlg8CcoWxlprxfwxwWitNPyckMmWpNNqlySEEBZNgrIF6untwsTbOgLwv2v2k19UqnJFQghhuSQoW6ipg/xp7+5AZk4hC345pHY5QghhsSQoWyh7nZboe4MA+HJXKrGp51WuSAghLJMEZQvWv4sH94f6oCjw0spEikplhREhhLiWBGUL98qIADz0Oo5l5bN463G1yxFCCIsjQdnCuTromHVPIACLfjvG0dN5KlckhBCWRYJSMCKoLYO6t6HEoDB9VSJGo0xvJ4QQl0lQCjQaDXNG9cRRpyU29QLf/JWqdklCCGExJCgFAO1c7XlpWHcA5v9ymJPZl1SuSAghLIMEpTD7x80d6NPelfyiUl5ds19WGBFCCCQoxVWsrDTMHxOMjVbDlkNZrE3MVLskIYRQnQSlKKerpxOTBnYBYNaPB8guKFa5IiGEUJfFBOW8efPQaDRMnTq12nbff/893bt3x87OjqCgINatW9c4BbYgT93RmS5t9JzNL2buuiS1yxFCCFVZRFDGxMSwZMkSgoODq233559/8tBDDzFhwgT27t3LqFGjGDVqFPv372+kSlsGW2st88cEodHAd3sy2HHsrNolCSGEalQPyvz8fKKioli6dClubm7Vtn3vvfcYOnQoL7zwAgEBAcyZM4c+ffrw4YcfNlK1LUdoB3cevqUDAC+vTuRSsUxvJ4RomVQPykmTJjFixAgiIiKu23bnzp0V2g0ZMoSdO3c2VHkt2gtDutHWxY7UcwUs3HJE7XKEEEIVqgbl8uXLiYuLIzo6ukbtT506haenZ7l9np6enDp1qsrnFBUVkZubW24TNeNkZ8Mbo3oC8PEfyez/O0flioQQovGpFpTp6elMmTKFb775Bjs7uwZ7n+joaFxcXMybr69vg71XczQowJMRwW0xGBWmr0qg1GBUuyQhhGhUqgVlbGwsWVlZ9OnTB2tra6ytrdm2bRvvv/8+1tbWGAwVz4l5eXlx+vTpcvtOnz6Nl5dXle8zY8YMcnJyzFt6enq9/y7N3azIQFzsbdj/dy6f7khWuxwhhGhUqgXloEGDSExMJD4+3ryFhYURFRVFfHw8Wq22wnP69evHli1byu3btGkT/fr1q/J9bG1tcXZ2LreJ2mntZMsrIwIAeGfTEVLPXVS5IiGEaDx1CsovvviCtWvXmn9+8cUXcXV1JTw8nNTUmk2o7eTkRM+ePcttjo6OtGrVip49TefFxo8fz4wZM8zPmTJlCr/88gv//ve/OXToELNmzWLPnj1Mnjy5Lr+GqIX7Q30I79yKwhIjL69OlOnthBAtRp2Ccu7cudjb2wOmK1EXLVrEW2+9hYeHB88++2y9FZeWlkZm5pVp1MLDw1m2bBn//e9/CQkJYcWKFaxZs8YcrKLhaDQaou8Nwtbaih3HzrEiNkPtkoQQolFolDp0DRwcHDh06BDt27fnpZdeIjMzky+//JIDBw5wxx13cObMmYaotV7k5ubi4uJCTk6ODMPWwZJtx4lefwgXexs2PzeA1k62apckhBB1UtM8qFOPUq/Xc+7cOQA2btzI4MGDAbCzs+PSJVmeqTmbcGtHAts5k3OphNd/Pqh2OUII0eDqFJSDBw9m4sSJTJw4kSNHjjB8+HAADhw4gJ+fX33WJyyMtdaK+WOC0Vpp+GnfSbYknb7+k4QQogmrU1AuWrSIfv36cebMGVauXEmrVq0A0y0fDz30UL0WKCxPT28XJt7aEYD/XbOf/KJSlSsSQoiGU6dzlE2ZnKOsH5eKDQxZ+Dtp5wt4pF8HZo+UC6qEEE1Lg56j/OWXX9i+fbv550WLFtGrVy/GjRvHhQsX6vKSoomx12mJvjcIgC93pRKbKv/uQojmqU5B+cILL5jnTE1MTOT5559n+PDhJCcn89xzz9VrgcJy9e/iwX2hPigKTF+ZQHGpTG8nhGh+6hSUycnJ9OjRA4CVK1dy9913M3fuXBYtWsT69evrtUBh2V4ZHoCHXsfRrHwWbz2udjlCCFHv6hSUOp2OgoICADZv3sxdd90FgLu7u6zO0cK4OeqYGRkIwIe/HeXo6TyVKxJCiPpVp6C89dZbee6555gzZw67d+9mxIgRABw5cgQfH596LVBYvruD2zKoextKDArTVyViNLao68OEEM1cnYLyww8/xNramhUrVrB48WK8vb0BWL9+PUOHDq3XAoXl02g0zBnVE0edltjUC3zzV83m+xVCiKZAbg8R9eaLP1OY+eMB9LbWbHrudtq62KtdkhBCVKmmeWBd1zcwGAysWbOGpKQkAAIDA7nnnnsqXR5LtAz/uKUDP8T/TVxaNq+u2c/S8WFoNBq1yxJCiBtSp6HXY8eOERAQwPjx41m1ahWrVq3iH//4B4GBgRw/Llc+tlRaKw3zxgRjo9WwOSmLdYmn1C5JCCFuWJ2C8plnnqFz586kp6cTFxdHXFwcaWlpdOzYkWeeeaa+axRNiL+nE0/f0QWAmT/uJ7ugWOWKhBDixtQpKLdt28Zbb72Fu7u7eV+rVq2YN28e27Ztq7fiRNP09MDOdGmj52x+MXPXJaldjhBC3JA6BaWtrS15eRXvl8vPz0en091wUaJps7XWMn9MEBoNfLcngz+PnVW7JCGEqLM6BeXdd9/NE088wV9//YWiKCiKwq5du3jyySe555576rtG0QSFdnDnHzd3AGDG6kQKSwwqVySEEHVTp6B8//336dy5M/369cPOzg47OzvCw8Pp0qULCxcurOcSRVP14tBueDnbkXqugIWbj6pdjhBC1MkN3Ud57Ngx8+0hAQEBdOnSpd4KayhyH2Xj2nTwNI9/uQetlYYfJvWnp7eL2iUJIQRQ8zyocVDWZlWQd955p8ZtG5sEZeObtCyOtQmZ9PR2Zs3T/bHW1mkgQwgh6lW9Tziwd+/eGrWTG8zFtWZFBrL96Fn2/53LZztSePz2TmqXJIQQNSZT2IlG8V1MOi+uTMDOxoqNUwfQvpWD2iUJIVq4muaBjIGJRnF/mA/hnVtRWGLk5dWJtLC/z4QQTZgEZV3t+QzOJ6tdRZOh0WiYOzoIW2srth87y8q4v9UuSQghakSCsi7OHIafn4UPQmH1U3D2mNoVNQl+Ho48O9gfgDk/H+RMXpHKFQkhxPVJUNaFokDnO0ExwL5lsKgvrJgAWTJd2/VMvLUjge2cyblUwus/H1S7HCGEuC4Jyrpo0x0eXgUTfwX/YaAYYf8K+KgffDceTiWqXaHFstZaMX9MMForDT/tO8mvh06rXZIQQlRLgvJG+ITCuOXwz98hIBJQ4OAP8J9b4f8egr/j1K7QIvX0dmHCrR0B+N/V+8kvKlW5IiGEqJoEZX1oGwIPfA1P7YSeYwANHF4HSwfC1/dB+m61K7Q4z0b4097dgZM5hby94bDa5QghRJUkKOuTZw+471OYtBuCHwSNFo5tgk8Gwxf3QMp2tSu0GPY6LXNHBwHwxc4UYlMvqFyREEJUToKyIbT2h3uXwL/2QO+HwcoakrfB5yPg02Fw/DfTBUEt3K1dPbgv1AdFgRmrEiguNapdkhBCVCBB2ZDcO8HID+GZvRD2GGh1kPYnfDXK1Ms8srHFB+YrwwPw0Os4cjqf/2w7rnY5QghRgQRlY3BtD3e/C8/Ew81PgrUdZMTAsvvhv3fAobUtNjDdHHW8FhkIwIe/HuNYVsUFwYUQQk0SlI3JxRuGzYcpCRD+L7BxgMx4WD7OdKXsgdVgbHnDj5HBbbmzexuKDUamr0zEaGyZfzQIISyTqkG5ePFigoODcXZ2xtnZmX79+rF+/fpqn7Nw4UK6deuGvb09vr6+PPvssxQWFjZSxfXEyRPuegOmJsKtz4HOCU7vh+8fhY9ugYTvwWhQu8pGo9FomDOqJ446LXtSL/DN7jS1SxJCCDNVg9LHx4d58+YRGxvLnj17uPPOOxk5ciQHDhyotP2yZcuYPn06M2fOJCkpiU8++YRvv/2Wl19+uZErryeOHhAxE6YmwICXwNYFzh6GVRPhw76w9xswlKhdZaPwdrXnxaHdAZi//hCZOZdUrkgIIUwsbpktd3d3FixYwIQJEyo8NnnyZJKSktiyZYt53/PPP89ff/3F9u01u/XCopfZKsyB3f+FnYvgUtntEq4d4NZnoVcUWOvUra+BGYwK9//nT+LSsokI8GTp+FBZ31QI0WCa3DJbBoOB5cuXc/HiRfr161dpm/DwcGJjY9m923QD/4kTJ1i3bh3Dhw+v8nWLiorIzc0tt1ksOxe4/QWYuh8Gvw6OrSE7FX6eCu/3ht1LoaSJDTPXgtZKw7wxwdhoNWxOOs26xFNqlySEEOr3KBMTE+nXrx+FhYXo9XqWLVtWbfC9//77TJs2DUVRKC0t5cknn2Tx4sVVtp81axazZ8+usN8ie5TXKi6A2M9hx3uQXxYaei/oPwVCHwVd81z8+J1NR3h/y1GsrTQM7N6G+0J9GNitDTpri/m7TgjRDNS0R6l6UBYXF5OWlkZOTg4rVqzg448/Ztu2bfTo0aNC261bt/Lggw/yxhtvcPPNN3Ps2DGmTJnC448/zquvvlrp6xcVFVFUdGU5p9zcXHx9fZtGUF5WUgh7v4LtCyE3w7TPsTX0mwx9J4Ctk6rl1beiUgP//CqWrYfPmPe5O+oY2asd94X6ENjORcXqhBDNRZMJymtFRETQuXNnlixZUuGx2267jVtuuYUFCxaY93399dc88cQT5OfnY2V1/R6HRZ+jvJ7SYtOyXn+8YxqSBbB3g1smwc1PmIZum5Gjp/NYEZfBqri/y61d2d3LiftCfRjV2xsPva2KFQohmrImd47yMqPRWK4HeLWCgoIKYajVagGwsLxvGNY605Drv2Jh1GJw72y66Oe3N+DdIPhtLhScV7vKetPV04kZwwLYOf1OPvufvowIbotOa8WhU3m8sTaJW+ZuYeIXe/hl/ymZ/k4I0WCs1XzzGTNmMGzYMNq3b09eXh7Lli1j69atbNiwAYDx48fj7e1NdHQ0AJGRkbzzzjv07t3bPPT66quvEhkZaQ7MFkFrA73GQfADsH8V/PE2nDkE2+bDzo/gpseh3yTT7SfNgLXWioHd2jCwWxuyC4r5KSGTFbEZ7EvPZnPSaTYnncbNwYaRvbzLhmad5WpZIUS9UXXodcKECWzZsoXMzExcXFwIDg7mpZdeYvDgwQDccccd+Pn58fnnnwNQWlrKm2++yVdffcXff/9N69atiYyM5M0338TV1bVG79mkh16rYjRC0o/w+wLTxAVgmvUn7DEIf8Y0wUEzdCwrjxWxf7MqLoOsSoZmR/byprWTDM0KISrXZM9RNrRmGZSXGY1wZD1se8s0NR6Y5pXt84jpSlkXb1XLayilBiPbj51lRWwGGw+eNg/Daq00DOzWmjF9fLgzoA221i1o1EEIcV0SlFVo1kF5maLAsc2mwMwoWzRaq4Pe/zBNXuDaXt36GlBOQQk/JZxkZVwGe9OyzftdHWwYGdKO+0J96ektQ7NCCAnKKrWIoLxMUUzrYG57C1J3mPZZWUPIg6Y5Zlt1Vre+BnYsK5+VcRmsisvgdO6VodlunmVDs73b0cbJTsUKhRBqkqCsQosKyqul7IDf34ITW00/a6wgaCzc9rxpoelmzGBUzEOzGw6cKjc0e4d/a8aE+jBIhmaFaHEkKKvQYoPysvTdph7msU1lOzQQONo0dZ5nxUkempucSyX8nHCSlbEZxF01NOtib2Oe0CDI20WGZoVoASQoq9Dig/Kyv+Pg97fh8Nor+wIiTYHZNkS9uhrR8TP5rIw1TWhwKvfKHLr+nnrThAa9vGnjLEOzQjRXEpRVkKC8xqlE020lB38Eyj4K/kPh9hfBJ1TV0hqLwaiw46qh2aKrhmZv7+rBfaG+DApog52NDM0K0ZxIUFZBgrIKWYdMExfsXwlK2Sw3nQfBgBeh/S3q1taIcgtLWFs2oUFs6gXzfhd7G+4JMQ3NBvvI0KwQzYEEZRUkKK/j7DHY/g7sWw6KwbTP7zbTwtJ+t0ILCogTZy5fNfs3mTlXhma7tDENzY7u7Y2nDM0K0WRJUFZBgrKGzifD9nchfhkYS0z72vczncPsfGeLCkyDUWHn8XOsiE1n/f4rQ7NWGrjdvzX3hfoQEeApQ7NCNDESlFWQoKyl7HTTephxX4Kh7F5E71DTOUz/IS0qMME0NLuubGh2z1VDs8521tzTyzShQYgMzQrRJEhQVkGCso5yM+HP92HPZ1B6ybTPK9h0DrPbCKjBEmfNTfLZi2VXzWZw8qqh2c6tHbkv1JfRvb3xcpGhWSEslQRlFSQob1B+Fuz8EHZ/DCUXTfva9IDbp0GPUWDV8oYfjUaFnSfOsSI2g/X7MyksuTI0e1tX09Ds4B4yNCuEpZGgrIIEZT25eA52fQS7/wtFuaZ9Hv5w2zToOQa0qq7gppq8whLWJZqGZmNSrgzNOtlZE1l21WxvX1cZmhXCAkhQVkGCsp5dyoa/lphCszDbtM+to2lqvJAHTWtntlApZy+ar5r9O/uSeX+n1o7cF+rDvb19ZGhWCBVJUFZBgrKBFOZCzFLYuQgKzpn2ubSHW6eaVi2xbrnrQhqNCrvKhmbXXTM0e2vX1ozp482QQC8ZmhWikUlQVkGCsoEVX4Q9n8KO9+FilmmfUztTYPYZDzb2qpantrzCEtYnnmJFbAa7U86b9zvZWXN3sGlotk97GZoVojFIUFZBgrKRlFwy3VKyfSHknTTt03tC+DMQ9j+gc1S1PEuQeu4iK+P+ZmVsRvmhWQ9HxoT6cG8fb9q6tOw/LIRoSBKUVZCgbGSlRbD3a9PkBTnppn0OraDfZLjpcbB1Urc+C2A0KuxKLrtqNvEUl0pMMyJpNHBrFw/uC/Xhrh5e2OtkaFaI+iRBWQUJSpWUFkPCcvjj33AhxbTPzhVueRpu/ifYu6pYnOXILyo1XzW7O/mqoVlba+4OaVs2NOsmQ7NC1AMJyipIUKrMUAr7V5iW+Dp31LTP1tkUlrc8DQ7u6tZnQdLOFbAyLoOVcRlkXLgyNNvRw5ExfbwZ3ccHb1cZmhWiriQoqyBBaSGMBji4BrYtgDNJpn06PfSdaBqW1bdWtTxLYjQq/JV83jyhQUHxlaHZ/p1NQ7NDAmVoVojakqCsggSlhTEa4dDP8PtbprUxAaztIewx6PUQOLYx9TJb8P2YV7tYVMr6/adYEZvOrhNXhmb1ttaMCGrLfWE+hHWQoVkhakKCsgoSlBZKUeDIBtg2H07GVXzczsV0EZCDR9l/W4Fjq6r32To3+wnb089fGZpNP39laNavlQNj+vhwb6gMzQpRHQnKKkhQWjhFgeNbTCuWnD4Il85fWUi6NqxsahaoV++z1tX/79MIjEaF3Smmodl1ieWHZsM7tzIPzTroWua0gkJURYKyChKUTYzRAIU5cPGsacafgsv/PWeab7ayfZcna68tW2fTMO91e60epnZ2rhbXa71YVMov+00TGuw8cc68X29rzfAgL+4L9aWvnwzNCgESlFWSoGwBSi5dCc7qAtW87zwohtq/j0ZbMTwrC9Srg9am8eZ2TT9fwKq4v1kRl15uaLZD2dBsZEg7/Fo5SGiKFkuCsgoSlKICoxGKcqoI1LIgvTZki/Pq9l46fcXwrCxQHcv+a+d6w2t9Go0KMVcNzV4svvJHQRsnW/r6udPXz42+Hd3p7uWM1kqCU7QMEpRVkKAU9aK06Jpea2WBes0+Y2nt30djBfbu1wnUa/bpHKp8uYJi09DsyjjThAYlhvL/93eytaZPBzdu6uhOXz93gn1cZLJ20WxJUFZBglKoQlFM63bWJFAv91qLcur2XjYOZcHpXm2gFtk4c/A8xGSWsiO9iNi0HPKLyoe5TmtFsI8LfTu6c5OfO306uOFiL7fqiOZBgrIKEpSiySgtNl31Wy5Qz1XfkzUU1/ntFJ0TpTaO5OPABYMdp4p0nC+1JU9xIB9703819jg5u9HWsw0d2nnh396bVu4eYOdsmrfXxsHiLnASoio1zQO5XlwIS2WtAycv01YTigLF+dX0Wq8J2MJs0zqixhIANMV52BTn4Qa4AZ0AKht1LQCSy7Yd15Sg0YKtExo7Z9NVxLZOV/5rd/XPztf87FTWxsX03xa8fqmwPBKUQjQXGs2VwHHvWPPnlRRCUZ5paLgo1/S/C3PL7yv7uTD/ArnZF7iUn42xMAeb0nycKEDPJbQaBY1iKAvg7Bv7XbS21wnXqwPYpfJA1jmBVr7ixI2TT5EQLZ2NnWmrwfy6dmXbZbmFJcSlXiAm+RwJJzJJPpmJreEiTlzCSWMK0FbWRQS4K3R2VmjvWEobXTHWJXmVBHKeqUcMYCiCgiJTr/iGfjfHSgL38s/O1/RmL/9vl2sCVy/DyS2cnKMUQtSbolIDiRk57E45T0zyefakXiCvsPwFQjZaDT29XbjJz3RlbZifG64OZbMiGQ1lwZl3Te+2qt5uXrker3lfaWE9/laaanqzVYSrrTPYu5mGzR08bvgWH9EwmsTFPIsXL2bx4sWkpKQAEBgYyGuvvcawYcOqfE52djavvPIKq1at4vz583To0IGFCxcyfPjwGr2nBKUQjcdgVDhyOo+YlPPsTj5PTMp5TucWVWjn76mnr5+7+baUdjc6R21pcVlw5lwTrhWHkysG8FXPqctEFNeysga9p2lzanvlvLOTl+nny/sdWkmgNrImEZQ//fQTWq2Wrl27oigKX3zxBQsWLGDv3r0EBgZWaF9cXEz//v1p06YNL7/8Mt7e3qSmpuLq6kpISEiN3lOCUgj1KIpC+vlL7E45z56U8+xOOc+JMxWnHPR2tTdPgnCTnztd2ugbfwYhRTHN8nTdcK0icAvOmi6aooZfsZcD1ckL9FcFqdNVAav3kkCtR00iKCvj7u7OggULmDBhQoXH/vOf/7BgwQIOHTqEjU3d7uWSoBTCspzNLzKFZvIF9qSe58DJXAzG8l9Lbg42hF2eQcjPnZ7eLthom0BYGErg4hnIy4S8U1dtmZB/+sr+WgeqV8UAvbanau8ugXodTS4oDQYD33//PY888gh79+6lR48eFdoMHz4cd3d3HBwc+OGHH2jdujXjxo3jpZdeQqutfPaQoqIiioquDPXk5ubi6+srQSmEhcovKmVv2gVikk09zvj0bApLyq8gY2+jpXd717Lp99zp3d4VR9smfG2ioQTysyD/qiDNuypIL++/eKbmr2kO1Gs2vVf5IeAWHKhN5j7KxMRE+vXrR2FhIXq9ntWrV1cakgAnTpzg119/JSoqinXr1nHs2DGefvppSkpKmDlzZqXPiY6OZvbs2Q35Kwgh6pHe1prburbmtq6mq3CLS43sP5lDTNk5zpiUC+RcKuHP4+f487hphRStlYae7ZxNwVl2ntPdsQktm6a1ARdv01ady4Fq7pWeuqanWhaqF8+YpkzMzTBt1bGyKQtQz4rDvVcPATu4t9irf1XvURYXF5OWlkZOTg4rVqzg448/Ztu2bZWGpb+/P4WFhSQnJ5t7kO+88w4LFiwgMzOz0teXHqUQzYvRqHDsTL754qCY5POczKl4lWvn1o7mi4P6+rnj42bfclZKKS2Gi1lX9UqvHuo9fSVoa3P7zeVANYdqZRcmeTWpQG1yQ6+XRURE0LlzZ5YsWVLhsQEDBmBjY8PmzZvN+9avX8/w4cMpKipCp7v+X5ByjlKI5ifjQgF7Ui6Yb0s5mpVfoU1bFzvC/Ny5qewiIf82Tli19JVSzIF69ZDvqYo91doEqlZ3Ve+0qguT2ppun1E5UJvM0Ou1jEZjuR7g1fr378+yZcswGo1YlY2pHzlyhLZt29YoJIUQzZOPmwM+bg6M6m0aujx/sZg9KVeGavf/nUNmTiE/7TvJT/tOAuBib0NYBzdTeHZ0I8jbFZ11CztXZ60DFx/TVp1ygZpZcajX3EMtm284J920VUeruypEK7swqexnCwhUVXuUM2bMYNiwYbRv3568vDyWLVvG/Pnz2bBhA4MHD2b8+PF4e3sTHR0NQHp6OoGBgTzyyCP861//4ujRozz22GM888wzvPLKKzV6T+lRCtHyFBSXEp+WbepxppwnLjWbSyXl75G0tbail6+r+TxnaAc39E35AiE1lBabhnivvqK3sit9C87V/DXLBeo1Q71dIkDfps7lNokeZVZWFuPHjyczMxMXFxeCg4PNIQmQlpZm7jkC+Pr6smHDBp599lmCg4Px9vZmypQpvPTSS2r9CkKIJsBBZ014Fw/Cu3gAUGIwcvBkrnkihD2pFzh/sZi/ks/zV/J5+A2sNNDj8gVCZVtrJ5msvVrWOnD1NW3VuRyo1/ZIr73S19xDTTNt13ps4w0FZU1Z3DnKhiY9SiHEtRRF4fiZi+aLg3annCfjwqUK7Tp6OJrv5ezr506HVg4t5wIhNZQWlQXq6Yr3nuadgns+uP6VwtVoshfzNDQJSiFETWTmXCIm5YL5tpTDp/O49tuyjZNtWWiaLhDq7uWMtqVfINSESFBWQYJSCFEXOQUl7Ek1XRwUk3KehIxsSgzlvz6dbK3p08GNm8rOcQZ5uzTtiRCaOQnKKkhQCiHqQ2GJgfj0bFOPM/UCcakXyC8qv1KKlQa6tnEixNeFEF9XQnxc6ebl1DSm32sBJCirIEEphGgIpQYjh07lmSdC2JuWzancihMh2FpbEdjOmRBfV3r5uhLs44qfnOtUhQRlFSQohRCN5XRuIfvSs9mXkc2+9Bz2ZWRXWJ8TTPd0Bvu4EOLjaup5+rrQxsmuklcU9UmCsgoSlEIItRiNCinnLpYLzgMncykuNVZo287FjuCrgjPI2wUnu7qtmiQqJ0FZBQlKIYQlKS41cvhUXll4mnqfR7PyK1xhq9FA59Z6Qnxc6VV2zrO7l3PLm02oHklQVkGCUghh6fKLStn/d065Ydu/syve16nTWhHQzplePi7m3mcnD0eZw7aGJCirIEEphGiKzuQVkWDudZqGbbMLSiq0c7K1Jti3LDh9TBcMebnI+c7KSFBWQYJSCNEcKIpC2vkC4tOzScgw9T73n8ypsMg1mCZGuHyVbYiPK0E+LrjYy/lOCcoqSFAKIZqrUoORI6fzzec749OzOXI6D2Ml3/KdPBzL7u10IdjXlR5tnbGz0TZ+0SqSoKyCBKUQoiUpKC7lwMlcc3AmZOSQdr6gQjtrKw0BbZ0JKRu27eXrSufW+mY9JZ8EZRUkKIUQLd35i8Xsy8gmoewWlX3p2Zy7WFyhnaNOS09vF9OQbdnWzsWu2UyOIEFZBQlKIYQoT1EUMi5cMp3rzDD1PPf/nUNBsaFCWw+97qqJEUxDt64OOhWqvnESlFWQoBRCiOszGBWOZeWbhmwzsknIyOZQZh6llZzw7NDK4Up4+rgQ2M4Fe53ln++UoKyCBKUQQtRNYYnBfL4zIcN0m0ry2YsV2mmtNHTzLJsMvixAu7bRY21hk8FLUFZBglIIIepPdkExCRk5JGRkE192zvNMXlGFdvY2Wnp6O1/V83TF191e1fOdEpRVkKAUQoiGoygKp8omg49PN93fmfh3ToUlyADcHGzMoXm599lKb9totUpQVkGCUgghGpfRqHDibL45OBMysjmYmVth4WsAHzd787nOEB9Xejbg4tcSlFWQoBRCCPUVlRpIyswrG7I13aJy/EzF851WGvD3dDItQ1bPi19LUFZBglIIISxTbmEJ+zNyiL88p216TrWLX796dw96t3er+/vVMA8apj8rhBBC1JKznQ3hXTwI7+Jh3nf14tcJGTnEp5sWv45Ly26wIdlrSVAKIYSwWJ7OdtwV6MVdgV5A+cWvO7fWN0oNEpRCCCGaDCsrDZ1a6+nUSCEJYFl3fwohhBAWRoJSCCGEqIYEpRBCCFENCUohhBCiGhKUQgghRDUkKIUQQohqSFAKIYQQ1Whx91FenrEvNzdX5UqEEEKo6XIOXG8m1xYXlHl5eQD4+vqqXIkQQghLkJeXh4uLS5WPt7hJ0Y1GIydPnsTJyemGFgzNzc3F19eX9PT0JjG5utTbsKTehiX1NqyWWq+iKOTl5dGuXTusrKo+E9niepRWVlb4+PjU2+s5Ozs3iQ/WZVJvw5J6G5bU27BaYr3V9SQvk4t5hBBCiGpIUAohhBDVkKCsI1tbW2bOnImtra3apdSI1NuwpN6GJfU2LKm3ei3uYh4hhBCiNqRHKYQQQlRDglIIIYSohgSlEEIIUQ0JSiGEEKIaEpTVWLRoEX5+ftjZ2XHzzTeze/fuatt///33dO/eHTs7O4KCgli3bl0jVWpSm3o///xzNBpNuc3Ozq7Rav3999+JjIykXbt2aDQa1qxZc93nbN26lT59+mBra0uXLl34/PPPG7zOy2pb79atWyscX41Gw6lTpxq81ujoaPr27YuTkxNt2rRh1KhRHD58+LrPU+vzW5d61fz8Ll68mODgYPPN7v369WP9+vXVPkfN74ba1qv2d8O15s2bh0ajYerUqdW2a8hjLEFZhW+//ZbnnnuOmTNnEhcXR0hICEOGDCErK6vS9n/++ScPPfQQEyZMYO/evYwaNYpRo0axf/9+i6wXTLNaZGZmmrfU1NRGqRXg4sWLhISEsGjRohq1T05OZsSIEQwcOJD4+HimTp3KxIkT2bBhQwNXalLbei87fPhwuWPcpk2bBqrwim3btjFp0iR27drFpk2bKCkp4a677uLixYtVPkfNz29d6gX1Pr8+Pj7MmzeP2NhY9uzZw5133snIkSM5cOBApe3V/m6obb2g7nfD1WJiYliyZAnBwcHVtmvwY6yISt10003KpEmTzD8bDAalXbt2SnR0dKXtx44dq4wYMaLcvptvvln55z//2aB1Xlbbej/77DPFxcWlUWq7HkBZvXp1tW1efPFFJTAwsNy+Bx54QBkyZEgDVla5mtT722+/KYBy4cKFRqmpOllZWQqgbNu2rco2an9+r1aTei3p86soiuLm5qZ8/PHHlT5mScf2surqtZRjm5eXp3Tt2lXZtGmTMmDAAGXKlClVtm3oYyw9ykoUFxcTGxtLRESEeZ+VlRURERHs3Lmz0ufs3LmzXHuAIUOGVNm+PtWlXoD8/Hw6dOiAr6/vdf/CVJuax/dG9OrVi7Zt2zJ48GB27NihSg05OTkAuLu7V9nGko5vTeoFy/j8GgwGli9fzsWLF+nXr1+lbSzp2NakXrCMYztp0iRGjBhR4dhVpqGPsQRlJc6ePYvBYMDT07Pcfk9PzyrPMZ06dapW7etTXert1q0bn376KT/88ANff/01RqOR8PBwMjIyGrzeuqjq+Obm5nLp0iWVqqpa27Zt+c9//sPKlStZuXIlvr6+3HHHHcTFxTVqHUajkalTp9K/f3969uxZZTs1P79Xq2m9an9+ExMT0ev12Nra8uSTT7J69Wp69OhRaVtLOLa1qVftYwuwfPly4uLiiI6OrlH7hj7GLW71EGHSr1+/cn9RhoeHExAQwJIlS5gzZ46KlTUP3bp1o1u3buafw8PDOX78OO+++y5fffVVo9UxadIk9u/fz/bt2xvtPW9ETetV+/PbrVs34uPjycnJYcWKFTzyyCNs27atyvBRW23qVfvYpqenM2XKFDZt2qTqRURXk6CshIeHB1qtltOnT5fbf/r0aby8vCp9jpeXV63a16e61HstGxsbevfuzbFjxxqixBtW1fF1dnbG3t5epapq56abbmrUwJo8eTI///wzv//++3WXllPz83tZbeq9VmN/fnU6HV26dAEgNDSUmJgY3nvvPZYsWVKhrSUc29rUe63GPraxsbFkZWXRp08f8z6DwcDvv//Ohx9+SFFREVqtttxzGvoYy9BrJXQ6HaGhoWzZssW8z2g0smXLlirH9fv161euPcCmTZuqPQ9QX+pS77UMBgOJiYm0bdu2ocq8IWoe3/oSHx/fKMdXURQmT57M6tWr+fXXX+nYseN1n6Pm8a1LvddS+/NrNBopKiqq9DFL/OxWV++1GvvYDho0iMTEROLj481bWFgYUVFRxMfHVwhJaIRjXC+XBDVDy5cvV2xtbZXPP/9cOXjwoPLEE08orq6uyqlTpxRFUZSHH35YmT59urn9jh07FGtra+Xtt99WkpKSlJkzZyo2NjZKYmKiRdY7e/ZsZcOGDcrx48eV2NhY5cEHH1Ts7OyUAwcONEq9eXl5yt69e5W9e/cqgPLOO+8oe/fuVVJTUxVFUZTp06crDz/8sLn9iRMnFAcHB+WFF15QkpKSlEWLFilarVb55ZdfLLLed999V1mzZo1y9OhRJTExUZkyZYpiZWWlbN68ucFrfeqppxQXFxdl69atSmZmpnkrKCgwt7Gkz29d6lXz8zt9+nRl27ZtSnJyspKQkKBMnz5d0Wg0ysaNGyutVe3vhtrWq/Z3Q2Wuveq1sY+xBGU1PvjgA6V9+/aKTqdTbrrpJmXXrl3mxwYMGKA88sgj5dp/9913ir+/v6LT6ZTAwEBl7dq1Flvv1KlTzW09PT2V4cOHK3FxcY1W6+XbJ67dLtf4yCOPKAMGDKjwnF69eik6nU7p1KmT8tlnn1lsvfPnz1c6d+6s2NnZKe7u7sodd9yh/Prrr41Sa2V1AuWOlyV9futSr5qf38cee0zp0KGDotPplNatWyuDBg0yh05ltSqKut8Nta1X7e+GylwblI19jGWZLSGEEKIaco5SCCGEqIYEpRBCCFENCUohhBCiGhKUQgghRDUkKIUQQohqSFAKIYQQ1ZCgFEIIIaohQSlEM5eSkoJGoyE+Pl7tUoRokiQohRAVPProo4waNUrtMoSwCBKUQgghRDUkKIWwIH5+fixcuLDcvl69ejFr1iwANBoNixcvZtiwYdjb29OpUydWrFhRrv3u3bvp3bs3dnZ2hIWFsXfv3nKPGwwGJkyYQMeOHbG3t6dbt26899575sdnzZrFF198wQ8//IBGo0Gj0bB161bAtFbg2LFjcXV1xd3dnZEjR5KSkmJ+7tatW7nppptwdHTE1dWV/v37k5qaWm/HRwg1SFAK0cS8+uqrjBkzhn379hEVFcWDDz5IUlISAPn5+dx999306NGD2NhYZs2axbRp08o932g04uPjw/fff8/Bgwd57bXXePnll/nuu+8AmDZtGmPHjmXo0KFkZmaSmZlJeHg4JSUlDBkyBCcnJ/744w927NiBXq9n6NChFBcXU1payqhRoxgwYAAJCQns3LmTJ554Ao1G0+jHSIj6JAs3C9HE3H///UycOBGAOXPmsGnTJj744AM++ugjli1bhtFo5JNPPsHOzo7AwEAyMjJ46qmnzM+3sbFh9uzZ5p87duzIzp07+e677xg7dix6vR57e3uKiorKLXz79ddfYzQa+fjjj83h99lnn+Hq6srWrVsJCwsjJyeHu+++m86dOwMQEBDQGIdEiAYlPUohmphrF6Pt16+fuUeZlJREcHAwdnZ2VbYHWLRoEaGhobRu3Rq9Xs9///tf0tLSqn3fffv2cezYMZycnNDr9ej1etzd3SksLOT48eO4u7vz6KOPMmTIECIjI3nvvffIzMysh99YCHVJUAphQaysrLh25buSkpJ6fY/ly5czbdo0JkyYwMaNG4mPj+d//ud/KC4urvZ5+fn5hIaGllt5Pj4+niNHjjBu3DjA1MPcuXMn4eHhfPvtt/j7+7Nr1656rV+IxiZBKYQFad26dbleWG5uLsnJyeXaXBs8u3btMg9xBgQEkJCQQGFhYZXtd+zYQXh4OE8//TS9e/emS5cuHD9+vFwbnU6HwWAot69Pnz4cPXqUNm3a0KVLl3Kbi4uLuV3v3r2ZMWMGf/75Jz179mTZsmV1OBJCWA4JSiEsyJ133slXX33FH3/8QWJiIo888gharbZcm++//55PP/2UI0eOMHPmTHbv3s3kyZMBGDduHBqNhscff5yDBw+ybt063n777XLP79q1K3v27GHDhg0cOXKEV199lZiYmHJt/Pz8SEhI4PDhw5w9e5aSkhKioqLw8PBg5MiR/PHHHyQnJ7N161aeeeYZMjIySE5OZsaMGezcuZPU1FQ2btzI0aNH5TylaPoUIYTFyMnJUR544AHF2dlZ8fX1VT7//HMlJCREmTlzpqIoigIoixYtUgYPHqzY2toqfn5+yrffflvuNXbu3KmEhIQoOp1O6dWrl7Jy5UoFUPbu3asoiqIUFhYqjz76qOLi4qK4uroqTz31lDJ9+nQlJCTE/BpZWVnK4MGDFb1erwDKb7/9piiKomRmZirjx49XPDw8FFtbW6VTp07K448/ruTk5CinTp1SRo0apbRt21bR6XRKhw4dlNdee00xGAyNcOSEaDgaRbnmhIgQwmJpNBpWr14ts+YI0Yhk6FUIIYSohgSlEEIIUQ2ZcECIJkTOlAjR+KRHKYQQQlRDglIIIYSohgSlEEIIUQ0JSiGEEKIaEpRCCCFENSQohRBCiGpIUAohhBDVkKAUQgghqiFBKYQQQlTj/wFEQmhhipf3qwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.568 | Test PPL:  35.434 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into disk\n",
    "import pickle\n",
    "meta = {\n",
    "    'token_transform': token_transform,\n",
    "    'vocab_transform': vocab_transform,\n",
    "}\n",
    "meta_name = 'meta_multiplicative.pkl'\n",
    "pickle.dump(meta, open('models/meta_multiplicative.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product and geography are what make cream skimming work. '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2, 10015,    13,  7836,    16,    76,   101,  3149, 14292,    93,\n",
       "            4,     3], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,   700,    21,  3048,  1698,     5,   430,    25,   679,   687,\n",
       "        10186,     6,  1710,   308,     4,     3], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12]), torch.Size([1, 16]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 14410])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #batch_size, trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 14410])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 14410])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,  154, 2066,   14,  260,  269,  679,  687,   31,    6,  192,    5,\n",
       "           4,    3,    4], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "များ\n",
      "ပတ်သက်\n",
      "ညီမျှ\n",
      "တွင်\n",
      "အရေးကြီး\n",
      "ရက်\n",
      "င်\n",
      "မ်\n",
      "ဖြစ်သည်\n",
      "ကို\n",
      "ပိုမို\n",
      "သည်\n",
      "။\n",
      "<eos>\n",
      "။\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 8. Attention - multiplicative\n",
    "\n",
    "Let's display the attentions to understand how the source text links with the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16, 12])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = attentions[0, 0, :, :]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Product',\n",
       " 'and',\n",
       " 'geography',\n",
       " 'are',\n",
       " 'what',\n",
       " 'make',\n",
       " 'cream',\n",
       " 'skimming',\n",
       " 'work',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'များ',\n",
       " 'ပတ်သက်',\n",
       " 'ညီမျှ',\n",
       " 'တွင်',\n",
       " 'အရေးကြီး',\n",
       " 'ရက်',\n",
       " 'င်',\n",
       " 'မ်',\n",
       " 'ဖြစ်သည်',\n",
       " 'ကို',\n",
       " 'ပိုမို',\n",
       " 'သည်',\n",
       " '။',\n",
       " '<eos>',\n",
       " '။']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    #attention = attention.squeeze(1).cpu().detach().toList()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
