{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation + Transformer\n",
    "\n",
    "English-Myanmar Translation using Transformers\n",
    "\n",
    "Training for General Attention\n",
    "\n",
    "Maung Maung Kyi Tha : st125214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install numpy==1.26.4\\n!pip3 install torch==2.2.0\\n!pip3 install torchdata\\n!pip3 install torchtext==0.16.2\\n!pip3 install portalocker\\n!pip3 install datasets\\n!pip3 install spacy\\n!pip3 install matplotlib\\n!python3 -m spacy download en_core_web_sm\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# to be run only first time, if you haven't installed libraries\n",
    "'''\n",
    "!pip install numpy==1.26.4\n",
    "!pip3 install torch==2.2.0\n",
    "!pip3 install torchdata\n",
    "!pip3 install torchtext==0.16.2\n",
    "!pip3 install portalocker\n",
    "!pip3 install datasets\n",
    "!pip3 install spacy\n",
    "!pip3 install matplotlib\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Loading libraries\n",
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random, math, time\n",
    "import numpy\n",
    "\n",
    "# setting device to GPU cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Seet my seed\n",
    "SEED = 69\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Making sure we get the same results on each run\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Disable user warnings for neater output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using GPU device : NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "My torch library version : 2.2.0+cu118\n",
      "My torchtext library version : 0.16.2+cpu\n"
     ]
    }
   ],
   "source": [
    "# What is my device, and cuda versions\n",
    "print(f\"I am using GPU device : {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"My torch library version : {torch.__version__}\")\n",
    "print(f\"My torchtext library version : {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  2 21:14:14 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.14                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   48C    P0             18W /  132W |    5899MiB /   6141MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6596    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      7000    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      7792    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      8944    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      9492      C   ...0_x64__qbz5n2kfra8p0\\python3.12.exe      N/A      |\n",
      "|    0   N/A  N/A      9644    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      9660    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     10640    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     11232    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     11332    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11424    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12860    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13072    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14780    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18044    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     19776    C+G   ...n\\132.0.2957.127\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19868    C+G   ...2.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     21428    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     22184      C   ...0_x64__qbz5n2kfra8p0\\python3.12.exe      N/A      |\n",
      "|    0   N/A  N/A     23840    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     23864    C+G   ...5.9.2.0_x64__htrsf667h5kn2\\AWCC.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Checking detailed GPU info\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset\n",
    "\n",
    "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English-myanmar parallel dataset from torchtext.datasets \n",
    "import torchtext, datasets\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TRG_LANGUAGE = 'mm'\n",
    "\n",
    "# I've experimented with two different english-myanmar parallel datasets here\n",
    "\n",
    "# Import parallel dataset by Aung Kaung Htet\n",
    "dataset = datasets.load_dataset('akhtet/myanmar-xnli')\n",
    "\n",
    "# Import parallel dataset uploaded from Christan bible translation\n",
    "#dataset = datasets.load_dataset('st125338/en_my_nlp_a3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 5010\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking structure of parallel dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing for Christan bible translation\n",
    "# train = [(row['en'], row['my']) for row in dataset['train']]\n",
    "# val = [(row['en'], row['my']) for row in dataset['validation']]\n",
    "# test = [(row['en'], row['my']) for row in dataset['test']]\n",
    "\n",
    "# Processing for parallel dataset by Aung Kaung Htet\n",
    "# since this dataset has two separate parallel sets, we will choose second set\n",
    "train = [(row['sentence2_en'], row['sentence2_my']) for row in dataset['train']]\n",
    "val = [(row['sentence2_en'], row['sentence2_my']) for row in dataset['validation']]\n",
    "test =  [(row['sentence2_en'], row['sentence2_my']) for row in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Product and geography are what make cream skimming work. ', 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။'), ('You lose the things to the following level if the people recall.', 'လူတွေပြန်ခေါ်ရင် အောက်ပါအဆင့်အထိ ဆုံးရှုံးသွားမယ်။'), ('A member of my team will execute your orders with immense precision.', 'ကျွန်ုပ်၏အဖွဲ့သားတစ်ဦးသည် သင်၏အမိန့်စာများကို အလွန်တိကျစွာ ဆောင်ရွက်ပေးပါမည်။'), ('This information belongs to them.', 'ဒီအချက်အလက်က သူတို့ပိုင်တယ်။'), ('The tennis shoes have a range of prices.', 'တင်းနစ်ဖိနပ်များသည် ဈေးနှုန်းအမျိုးမျိုးရှိသည်။'), (\"I'm upset that my walkman broke and now I have to turn the stereo up really loud.\", 'ကျွန်တော့်ရဲ့ လမ်းလျှောက်သမား ပြတ်သွားလို့ စိတ်မကောင်းဖြစ်ပြီး အခု စတီရီယိုကို တကယ် အသံကျယ်အောင် ပြန်ဖွင့်ရမှာ ဖြစ်ပါတယ်။'), ('Most of the Christian mosaics were destroyed by Muslims.  ', 'ခရစ်ယာန် ဗလီစာ အများစုကို မူဆလင်များက ဖျက်ဆီးခဲ့သည်။'), (\"Slate had an opinion on Jackson's findings.\", 'Slate သည် Jackson ၏တွေ့ရှိချက်အပေါ်အမြင်တစ်ခုရှိသည်။'), ('Heterosexuals.', 'ကဿာမိ။'), ('Place des Vosges is constructed entirely of gray marble.', 'Place des Vosges ကို မီးခိုးရောင် စကျင်ကျောက်ဖြင့် လုံး၀ တည်ဆောက်ထားသည်။')]\n",
      "[('He called his mom as soon as the school bus dropped him off.', 'ကျောင်းကားက သူ့ကို ချပေးပြီးပြီးချင်း သူက သူ့အမေကို ခေါ်ခဲ့တယ်။'), (\"He didn't say a word.\", 'သူ စကားတစ်လုံးမပြောခဲ့ဘူး။'), ('He told his mom he had gotten home.', 'သူ အိမ်ပြန်ရောက်ပြီလို့ သူ့အမေကို ပြောခဲ့တယ်။'), ('I have never been to Washington so when I was assigned there I got lost trying to find the place.', 'ဝါရှင်တန်ကို ကျွန်တော် တစ်ခါမှမရောက်ဖူးတာကြောင့် ကျွန်တော့်ကို အဲ့ဒီကို တာဝန်ပေးခံရ သောအခါ နေရာရှာရင်းနဲ့ လမ်းပျောက်ခဲ့တယ်။'), ('I knew exactly what I needed to do as I marched to Washington.', 'ဝါရှင်တန်ကို ငါချီတက်ခဲ့တာနဲ့ ငါ ဘာလုပ်ဖို့ လိုခဲ့လိုဆိုတာကို ငါအတိအကျ သိခဲ့တယ်။'), ('I was not quite certain what I was going to do so I went to Washington where I was assigned to report.', 'ငါ ဘာလုပ်ရမယ်ဆိုတာ ငါတော်တော် မသေချာခဲ့ဘူး ဒါကြောင့် ငါ တာဝန်ပေးခံရတဲ့ ဝါရှင်တန်ကို သတင်းပို့ဖို့ သွားခဲ့တယ်။'), ('He was the first to be invited and enjoyed the experience.', 'သူဟာ ပထမဆုံးဖိတ်ခံခဲ့ရပြီး အတွေ့အကြုံကို ခံစားပျော်ရွှင်ခဲ့တယ်။'), (\"He wasn't allowed to attend.\", 'သူ တက်ရောက်ခွင့်မရခဲ့ဘူး။'), (\"He wasn't allowed to go to the museum's opening.\", 'သူ့ကို ပြတိုက်ဖွင့်ပွဲ သွားဖို့ ခွင့်မပြုခဲ့ဘူး။'), ('After I said yes, it ended.', 'ငါ အင်း လို့ ပြောပြီးနောက် ၊ အဲ့ဒါ ပြီးသွားခဲ့တယ်။')]\n",
      "[('I havent spoken to him again.', 'ငါ သူ့ကို စကား ထပ်မပြောဖြစ်ဘူး။'), ('I was so upset that I just started talking to him again.', 'ငါ အရမ်းစိတ်မကောင်းဖြစ်လို့ သူကို တဖန် စကားစပြောရုံပါပဲ။'), ('We had a great talk.', 'ငါတို့ စကားကောင်းခဲ့တယ်။'), ('I was not aware that I was not the only person to be at the field that day.', 'အဲ့ဒီနေ့က ကွင်းထဲမှာ ရှိတဲ့သူက ကျွန်တော်တစ်ယောက်ထဲပဲမဟုတ်လို့ ကျွန်တော် သတိမထားမိခဲ့ဘူး။'), ('I was under the impression that I was the only one with that number at the AFFC Air Force Career field.', 'ကျွန်တော် က အေအက်ဖ်အက်ဖ်စီ လေတပ် အသက်မွေးဝမ်းကြောင်း လုပ်ငန်း မှာ အဲလို နံပါတ်နဲ့ တစ်ယောက်တည်းသောသူ လို့ ကျွန်တော် ထင်မြင်ခဲ့တယ်။'), ('We all were given the same exact number no matter what privileges we were promised to be granted, it was all a lie.', 'အခွင့်ထူးတွေ ခွင့်ပြုပေးဖို့ ကျွန်တော်တို့ကို ကတိပေးထားခဲ့ပေမယ့် ကျွန်တော်တို့အားလုံး အတိအကျ တူညီတဲ့ အရေအတွက်တွေ ပေးခြင်းခံရတယ်၊ ဒါတွေ အားလုံးက အလိမ်အညာပဲ။'), ('I was never told anything about meeting anyone.', 'တယောက်ယောက်နဲ့ တွေ့ဖို့အကြောင်း ငါ ဘယ်တုန်းကမှ အပြောမခံခဲ့ရဘူး။'), ('I was told a guy would be called in for me to meet.', 'ငါ့တွေ့ဖို့ ယောက်ျားလေးတစ်ယောက်ကို ခေါ်သွင်း လိမ့်မယ်လို့ ငါ့ကိုပြောခဲ့တယ်။'), ('The guy showed up a bit late.', 'အဲ့ဒီ ယောက်ျားလေးဟာ အနည်းငယ် နောက်ကျပြီးမှ ရောက်လာခဲ့တယ်။'), ('I want to tell you everything I know about that!', 'အဲ့ဒါနဲ့ ပတ်သက်ပြီး ငါ သိသမျှကို မင်းကို ပြောပြချင်တယ်!')]\n"
     ]
    }
   ],
   "source": [
    "#so this is a datapipe object; very similar to pytorch dataset version 2 which is better\n",
    "print(train[0:10])\n",
    "print(val[0:10])\n",
    "print(test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Product and geography are what make cream skimming work. ',\n",
       " 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking What does it looks like\n",
    "sample = next(iter(train))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of training dataset\n",
    "train_size_all = len(list(iter(train)))\n",
    "train_size_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_part1 : 137445\n"
     ]
    }
   ],
   "source": [
    "# Since The size is too much (400,000 lines), I will reduce the train size into 35% of original,\n",
    "# and then split again into train, val and test datasets\n",
    "# I will not use random split, but just split by index to make the train set consistent between the three model experimentations\n",
    "\n",
    "# Define the split ratio\n",
    "split_ratio = 0.35\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(train) * split_ratio)\n",
    "\n",
    "# Divide the train dataset into two parts\n",
    "train_part1 = train[:split_index]\n",
    "print(f'size of train_part1 : {len(train_part1)}')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "generator = torch.Generator().manual_seed(69)\n",
    "\n",
    "# Now splitting again\n",
    "train_size_all = len(list(iter(train_part1)))\n",
    "train_size = int(0.7 * train_size_all)\n",
    "val_size = int(0.2 * train_size_all)\n",
    "test_size = train_size_all - (train_size + val_size)  # Ensure all data is included\n",
    "\n",
    "# Perform the split again for final train, val and test\n",
    "train, val, test = torch.utils.data.random_split(train_part1, [train_size, val_size, test_size], generator)\n",
    "\n",
    "# after this, newly sized train, val and test will be used for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final training\n",
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final validation\n",
    "val_size = len(list(iter(val)))\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final test\n",
    "test_size = len(list(iter(test)))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n",
    "\n",
    "**Note**: the models must first be downloaded using the following on the command line: \n",
    "```\n",
    "python3 -m spacy download en_core_web_sm\n",
    "```\n",
    "For Myanmar tokenizer, I will need to create a custom myanmar text tokenizer using PyICU Unicode Library.\n",
    "\n",
    "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myanmar word tokenizer with PyICU\n",
    "from icu import BreakIterator, Locale\n",
    "\n",
    "def pyicu_tokenizer(sentence):\n",
    "    bi = BreakIterator.createWordInstance(Locale(TRG_LANGUAGE))\n",
    "    bi.setText(sentence)\n",
    "    tokens = []\n",
    "    start = bi.first()\n",
    "    for end in bi:\n",
    "        token = sentence[start:end].strip()  # remove leading/trailing spaces\n",
    "        if token:  # only add non-empty tokens\n",
    "            tokens.append(token)\n",
    "        start = end\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': functools.partial(<function _spacy_tokenize at 0x0000017532DB80E0>, spacy=<spacy.lang.en.English object at 0x000001757174A150>),\n",
       " 'mm': <function __main__.pyicu_tokenizer(sentence)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining english and myanmar word tokenizers\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TRG_LANGUAGE] = pyicu_tokenizer\n",
    "token_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Product and geography are what make cream skimming work. \n",
      "Tokenization:  ['Product', 'and', 'geography', 'are', 'what', 'make', 'cream', 'skimming', 'work', '.'] ['ထုတ်ကုန်နှင့်', 'ပထဝီဝင်အနေအထားသည်', 'ခရင်မ်', 'skimming', 'ကို', 'အလုပ်ဖြစ်စေသည်။']\n",
      "('Product and geography are what make cream skimming work. ', 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။')\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "print(\"Sentence: \", sample[0])\n",
    "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]), token_transform[SRC_LANGUAGE](sample[1]))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text to integers (Numericalization)\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
    "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 10, 9, 0, 9]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see some example\n",
    "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marriage'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
    "\n",
    "#print 1816, for example\n",
    "mapping[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try unknown vocab\n",
    "mapping[0]\n",
    "#they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24533"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n",
    "\n",
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# reduce batch size to avoid GPU memory error\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# reduce batch size to avoid GPU memory error\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, mm in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([32, 24])\n",
      "Myanmar shape:  torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
    "print(\"Myanmar shape: \", mm.shape)   # (batch_size, seq len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model\n",
    "\n",
    "<img src=\"../figures/transformer-encoder.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        _src    = self.feedforward(src)\n",
    "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                           for _ in range(n_layers)])\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len    = src.shape[1]\n",
    "        \n",
    "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, src_len]\n",
    "        \n",
    "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutli Head Attention Layer\n",
    "\n",
    "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim  = hid_dim\n",
    "        self.n_heads  = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "                \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        #src, src, src, src_mask\n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        #Q=K=V: [batch_size, src len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        #Q = [batch_size, n heads, query len, head_dim]\n",
    "        \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
    "        #energy = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        #for making attention to padding to 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        #attention = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
    "        #x = [batch_size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
    "        #x = [batch_size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        return x, attention\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [batch size, src len, hid dim]\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder Layer\n",
    "\n",
    "<img src = \"../figures/transformer-decoder.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        #attention = [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        _trg = self.feedforward(trg)\n",
    "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
    "                 pf_dim, dropout, device,max_length = 100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                            for _ in range(n_layers)])\n",
    "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len    = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, trg len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            \n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        #attention: [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        #output = [batch_size, trg len, output_dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together (become Seq2Seq!)\n",
    "\n",
    "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 1\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
    "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(24533, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(14410, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=14410, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
    "hid_dim = 256\n",
    "enc_layers = 3\n",
    "dec_layers = 3\n",
    "enc_heads = 8\n",
    "dec_heads = 8\n",
    "enc_pf_dim = 512\n",
    "dec_pf_dim = 512\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX\n",
    "\n",
    "enc = Encoder(input_dim, \n",
    "              hid_dim, \n",
    "              enc_layers, \n",
    "              enc_heads, \n",
    "              enc_pf_dim, \n",
    "              enc_dropout, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(output_dim, \n",
    "              hid_dim, \n",
    "              dec_layers, \n",
    "              dec_heads, \n",
    "              dec_pf_dim, \n",
    "              enc_dropout, \n",
    "              device)\n",
    "\n",
    "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6280448\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3688960\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3688960\n",
      " 14410\n",
      "______\n",
      "17677642\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "# increase learning rate due to GPU compute limitations\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
    "\n",
    "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
    "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
    "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_len, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg    = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg    = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_len, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n",
    "\n",
    "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
    "\n",
    "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))\n",
    "test_loader_length  = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 19s\n",
      "\tTrain Loss: 5.028 | Train PPL: 152.574\n",
      "\t Val. Loss: 4.508 |  Val. PPL:  90.699\n",
      "Epoch: 02 | Time: 2m 18s\n",
      "\tTrain Loss: 4.389 | Train PPL:  80.580\n",
      "\t Val. Loss: 4.200 |  Val. PPL:  66.703\n",
      "Epoch: 03 | Time: 2m 15s\n",
      "\tTrain Loss: 4.215 | Train PPL:  67.725\n",
      "\t Val. Loss: 4.117 |  Val. PPL:  61.362\n",
      "Epoch: 04 | Time: 2m 16s\n",
      "\tTrain Loss: 4.155 | Train PPL:  63.749\n",
      "\t Val. Loss: 4.089 |  Val. PPL:  59.697\n",
      "Epoch: 05 | Time: 2m 15s\n",
      "\tTrain Loss: 4.105 | Train PPL:  60.638\n",
      "\t Val. Loss: 4.070 |  Val. PPL:  58.546\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs = 5\n",
    "clip       = 1\n",
    "\n",
    "# name of model - for general attention\n",
    "save_path = f'models/{model.__class__.__name__}_general.pt'\n",
    "model_name = f'{model.__class__.__name__}_general.pt'\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "    \n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    #lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.059 | Test PPL:  57.940 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into disk\n",
    "import pickle\n",
    "meta = {\n",
    "    'token_transform': token_transform,\n",
    "    'vocab_transform': vocab_transform,\n",
    "}\n",
    "meta_name = 'meta_general.pkl'\n",
    "pickle.dump(meta, open('models/meta_general.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product and geography are what make cream skimming work. '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2, 10015,    13,  7836,    16,    76,   101,  3149, 14292,    93,\n",
       "            4,     3], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,   700,    21,  3048,  1698,     5,   430,    25,   679,   687,\n",
       "        10186,     6,  1710,   308,     4,     3], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12]), torch.Size([1, 16]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 14410])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #batch_size, trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 14410])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 14410])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,  154,    5,    5,    4, 1562,    5, 1743,    6,    6,    8,    5,\n",
       "           4,    3,    3], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "များ\n",
      "ပတ်သက်\n",
      "သည်\n",
      "သည်\n",
      "။\n",
      "တ္\n",
      "သည်\n",
      "ဥာ\n",
      "ကို\n",
      "ကို\n",
      "မ\n",
      "သည်\n",
      "။\n",
      "<eos>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 8. Attention - General\n",
    "\n",
    "Let's display the attentions to understand how the source text links with the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16, 12])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = attentions[0, 0, :, :]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Product',\n",
       " 'and',\n",
       " 'geography',\n",
       " 'are',\n",
       " 'what',\n",
       " 'make',\n",
       " 'cream',\n",
       " 'skimming',\n",
       " 'work',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'များ',\n",
       " 'ပတ်သက်',\n",
       " 'သည်',\n",
       " 'သည်',\n",
       " '။',\n",
       " 'တ္',\n",
       " 'သည်',\n",
       " 'ဥာ',\n",
       " 'ကို',\n",
       " 'ကို',\n",
       " 'မ',\n",
       " 'သည်',\n",
       " '။',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    #attention = attention.squeeze(1).cpu().detach().toList()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApEAAANjCAYAAADyBkFtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrHElEQVR4nO3df3zN9f//8ceZcWZmQ8jY8vs3+TXyK0ZqqPxMrVRUpB9LKrJNZfSu+VUJ6Ze3RBIRaUWptKQfrBqa8ntMI7/2s+bMnMf3D9+d905TH08zr3O4XS+Xcynn9Trb/Zyd8zr383y+Xq9jU1UVAAAAwICP1QEAAADgfSiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAREXE6nVZHAAB4EUokABER8fE5szn48ccf5eTJk6KqFicCAHgySiQAlzVr1sgNN9wgBQUFYrPZKJIAgH9EiQTg0qdPH6lWrZr85z//ERERm81mcSIAgKeiRAKXqb/vA5mfny9Op1PuuOMO2bJli2RlZYmIMBoJADgrSiRwmSrcB3Lr1q0iIlKuXDnx8fGRwYMHS2Jiorz//vsiwmgkAODsKJHAZeyDDz6Q/v37S+/evWXjxo1y9OhRad68uYwdO1aWLl0q6enpVkcE8A84owKsRokELiN/f9Np27atzJ8/X06dOiWPPvqo9O7dWxISEqRmzZpy5MgROXLkyFlvB8B6hbMJS5YskZSUFIvT4HJkU3Z4Ai4Lp0+fljJlyoiIyO7du6VChQpSo0YN13T1V199JWvWrJGlS5dKp06dZOnSpXLzzTfL8uXLpWzZslZGB1CE0+l0Fcg//vhDgoODZciQITJp0iRp0qSJxelwOaFEApe4uXPnyjXXXCPt2rUTEZGYmBhZvXq1HD58WIYPHy6DBg2SLl26uNb/4Ycf5Ndff5W5c+fKH3/8IStXrpS2bdu6vXEBsIaquj74xcbGSkFBgXz44Yeyb98+uf766+Wll16SRo0aWZwSlwtKJHAJS0xMlLvuuktuuOEGGTdunOzcuVMefPBBeeWVVyQlJUU++ugjqVGjhjz66KMSHh7udluHwyFt27aV6667TmbNmmXNHQBwVi+99JL85z//kYSEBClfvrwcP35cbr31Vmnfvr3MmjWLIomLghIJXOIWLVoks2bNks6dO4uvr680bdpURowYISJnTi4+Y8YMCQgIkCeeeEK6desmImcKpN1ul7lz58r7778vCQkJUqFCBSvvBoAi7rrrLilXrpz897//dV3366+/SufOnaV79+4SHx8vTZs2tTAhLgfMTQGXqMKDYe666y55+OGH5dtvv5X58+dLZmama50+ffrIuHHj5M8//5SZM2fKunXrRETEbreLiMjGjRslLy+PaWzAQzidTnE6nXL06FHXuVxFznzwa9q0qUyYMEFWr14tEydOlEOHDlmYFJcD3hmAS5Cqio+PjxQUFIiIyPDhw2Xs2LFSrVo1WbNmjSQnJ7vW7d27tzz55JOyZ88e+eKLL1y3z83NlaNHj8qsWbOkfPnyVtwN4LL39zMj+Pj4iI+Pj9x3332yZs0aWbJkiYj874NflSpVZNiwYbJu3TqZPHnyRc+LywvT2cAlpugBMCdPnhQ/Pz/XskWLFslLL70kbdq0kUcffVSuvvpq17IffvhB2rdvLz4+Pq6d9wsKCsTX1/ei3wcA7gfRfPzxx3Lo0CEJCwuTBg0aiK+vr4wdO1bWrFkjcXFxMnToUMnIyJBhw4bJkCFDxN/fX+6991754YcfpFmzZhbfE1yqKJHAJaTom860adNk3bp14u/vL/Xr15cXX3xRREQWLlwoL7/8srRu3VrGjBkjLVu2dPsZRU8FBMAaRV/L48aNk7ffflvKli0rdrtdbrvtNhk3bpzk5+fLjBkzZNasWXLVVVdJQUGBVKxYUZKTk+Xzzz+XqKgo+eabb+TKK6+0+N7gUsV0NnCJKPqmM336dPnPf/4j7du3lyuvvFLef/99CQsLk2PHjsndd98tUVFRsm3bNpk4caLs2bPH7edQIAFrnT592vVa/v777+Xnn3+WhIQE2blzp9x7773y5ZdfysSJE6Vs2bIyY8YM+eGHH2TcuHEydepU+fnnn6VMmTLy2WefyZVXXinlypWz+N7gUsZIJEpV0anVwpJz7NgxqVq1qsXJLl0bN26URYsWyc033yw33nijiJw5ufigQYMkICBAvv32WxERee2112TTpk0yb948DpwBPEBSUpKEhYW5/r1kyRJJSEgQPz8/t6Owp0+fLu+//75cc8018uSTT0poaKhr2a5du+Sll16Sd999V77++mu3XVaAC413DpQqHx8f2bVrl8yfP19sNpssW7ZMRo0aJX/88YfV0S5JCQkJ8uCDD0pCQoJrCsvpdEqDBg1k4cKFkpqaKgsXLhQRkQceeEDmz58vPj4+fK0hYLFx48bJm2++Karqej1+/vnn8sknn8jPP/8seXl5buveeuut8tNPP0lMTIwcO3ZMRM7sA71p0ybJzMykQOKioESiVBUUFMj7778vI0aMkAceeEAiIyOlX79+7KNTSurVqyetW7eWY8eOyYcffigi//t+3auuukoCAwPdTvEj8r8juQFY55ZbbpFXXnlFbDabpKamiojIf//7X3nooYckKytLpk6dKhkZGa71x44dK7169RJ/f3+pUqWKiIj4+fnJ4MGD5Y033qBA4qLgsEuUKl9fX3n00Udl8+bN8sYbb8iwYcNk2LBhIiJ8jV4Jne3xa9asmUycOFHKlCkjq1evlurVq8sjjzwiIiIVK1YUX19f12l/ChXuewXAOtdcc42IiCxdulRmzJghkydPlj59+shzzz0nf/75p3z88cfi6+srjzzyiAQFBYmIyKRJk1y7CRVuD4qejQEobZRIlJrCjVqZMmXkyiuvlIiICPnggw+kffv28tBDD4mPjw9HAp+nogXy+++/l2PHjknNmjWlUaNGUr9+fRk/frxMnTpVpk2bJps2bZL69evL1q1bxeFwyOjRoy1OD+CfVKxYUapWrSovv/yy+Pj4SEREhMycOVPGjBkjH374ofj4+MiDDz4olStXFpEzHwKZTYBVKJEoFYUbtR9//FGOHz8ukydPFn9/f5k6dapER0eLiMhDDz3kKpD79++X2rVrWxnZaxR9w4iJiZEPPvhAsrKypGHDhlKvXj156aWXpEmTJq7H+YMPPpA2bdrI8OHD5YMPPhARTuMDeIKzzSb07dtXfH19Zfbs2TJjxgwREVeRfPzxx+X111+XWrVquWZ0RJhNgHUokbjgCqdXVqxYISNHjpQnnnhC6tatK9WrV5eHHnpIbDabxMTEiMiZIjl58mRJSUmR+fPn8/3M56DwDWPq1Kny9ttvy9KlS+Xaa6+VMWPGyBtvvCEnTpyQt956Sxo3bux6nNPT08XhcBT7GQCsUfTD4NKlS+XPP/+UoKAgGTx4sNxwww3idDrllVdecSuSL774otSuXVvuvPNOK6PDyxQ9/VuhC7Y7mcKjOZ1OqyOcl2+++UaDgoL0zTff1D///NNtWXp6uk6ePFltNpt26NBB/f39NSkpyaKk3uP06dOu/09LS9OuXbvqqlWrVFV17dq1GhAQoPfcc4+2aNFCBwwYoMePH1dV1ZSUFL3nnnu0a9eu+tJLL1kRHbDMqVOnrI7wr6Kjo7VKlSrasGFDbdiwod5+++2uZWvWrNGbb75Zb7jhBtdrvVBBQcHFjgov8/f+kJGRoT///PMF/R3sROGh9P+fvrPw08ORI0dk27Ztsnv3bitjnbN169ZJ165dZcSIEeLv7y8iZ6ZQRUSCg4MlOjpaPv/8c7nllltk69at0q5dOyvjejwtMmrx9ddfS3BwsIwbN07CwsLku+++k3vvvVdeeOEFmT9/vlxzzTXy4Ycfyo033igZGRnSrFkziY2NlRo1asiaNWuKHZ0NXKrWrVsnjzzyiIwdO1Z++ukn1zbISoWn71FVyczMlF9++UUSExMlMTFR4uLi5IcffpB+/fqJyJnvtX/44YclJydH1q9f77qdCF8KgH+nRUYfCwoK5PXXX5e77rpL2rZtK6+++uoF+z1MZ3ugosPMDodD5s+fL6tWrZIff/xR4uPjpUGDBhYn/L/t3r3btZEreoCNiMjWrVulTp060rNnT+nZs6eVMb1C0Y3BhAkT5OOPP5YPPvjA9UYze/Zsuf7662X48OEiItKoUSO54YYbpFWrVlKxYkUREWnQoIFMmTJF/P39pVKlSlbcDeCiWr9+vdx8880yePBgWbVqlXz77bdy1113yYgRI6Rs2bKWZCq6bT906JAcP35cRESqV68u1atXl0GDBomfn5+MHTtW+vfvLx9++KFERERIpUqVpH379iLCrig4NzabTf766y+ZOnWq/PDDD7Jlyxbp27evhIaGSps2bS7Y72Ek0gP5+PjIyZMnJSYmRgYNGiSTJk2S4OBgKVu2rDRu3NjqeP/oyJEjrv+/+uqr5auvvpKdO3eKj4+P69NzZmamvPvuu5KcnCwi//tUjX9W+Kaxd+9e2bJli8ycOVPq1avnWn7kyBH59ddfXW9OmzZtkhtvvFGmTp3qdkqf+vXrS3Bw8MW/A4AFfvrpJ3n22Wdl8eLFsnv3bqlXr54sWrRI3njjDTl16pQlmQpfo7GxsdK5c2cZMWKEpKSkuK738/OTvn37yowZM2T79u3StWtXETlz+h++FADnKikpSeLj46V58+by+eefS7du3WT//v3i4+MjdevWdZ1O6kKgRHqYjRs3ypQpU6RJkyby1VdfSY8ePSQ1NVUqVqwoTZo0kW7dulkd8aySkpJk8ODBsnjxYhERufPOO6Vdu3YydOhQ2bFjh9hsNsnPz5cZM2bI4sWLpU6dOiLCp+pz9cILL8iNN94oWVlZrpHowjeU6667TpxOp4SFhUmHDh1k+/bt8uCDD4rImZLu68uEA86ftxWX7du3S3JysmRkZMhVV10lIiIVKlSQV155RRo0aCDvvPOOzJs376IWyaKP4XvvvSeLFy+WZ555Rm6++WZxOBxyxx13uJYXFsm4uDgJDg52uy2n8cH/ZdWqVTJw4EDZvHmzjBw5Ur755huJiYmRlJQU2bRpk0yfPt11XtEL4oLuYYnz5nQ6dePGjWqz2fS2227T+Ph417ItW7ZomzZtdMOGDarqmTtUp6ena6dOnbRnz576wQcfqKpqYmKi9unTR/39/bV79+7apUsXrVatmv70008Wp/V8RQ+iUVXdsWOH1qhRQ202m37xxRduy/Ly8nTx4sX6xBNP6Lhx41wHEnji8+RyUHRn9r//HT1dYfaDBw/q3r179ffff7c4kZlly5ZplSpV9IorrlCbzaZ33nmn2/Ls7GwdPny4NmnSRN94442Lnu/999/XWbNmuX73qVOndMOGDVqrVi2NiIhwW9fhcLj+39ueR7DOH3/8od98841mZma6XT9lyhTt1auXpqenX9DfR4n0MJs3by52NPPzzz+v3bp185gN+j8dMZ6enq7XXXeddu3aVT/88ENVVc3KytLXX39dn3zySZ0xY4bu3r37Ykb1ej/++KMePnxYVVVTU1O1WrVqGh4erjt27PjX23n6EamXksLXQ2Zmpubm5qqq6scff3zBj4IsbYX3Y+XKldqkSRNt0aKF1qhRQ8eOHesV9+Xo0aN6/fXX6xtvvKE///yzPvTQQ3r11VfrM88847bNysrK0gceeED37dt3UfOdOHFCK1eurDabTZ9++mnX9U6nU7/55hsNCQnRvn37XtRMpaHwsT558qTFSS4v+/bt+8eC+Msvv2hgYKAuXLjwgv9eSqQH2Ldvnx45cuSsy3799Ve94oordNGiRRc5VXHZ2dmq+r9PxT/++KMmJia6rZOenq69evXS9u3bu4okzl3REYePP/5Ya9SoobNnz9Zjx46pquru3bu1SpUq2rt3b925c+dZb4eLy+l06h9//KHBwcH63nvv6aJFi9Rms+mKFSusjmbsiy++0ICAAJ01a5bm5+frtGnT1Gaz6dKlS62O9q++++47HThwoA4ZMkRPnDihqmdK/bhx47RDhw761FNPuRXJi3HqtLP9jp07d2qrVq00LCxM09LS3NbduHGjlilTRh9//PFSz1baPv30Ux06dKjbaCpKz8qVK7Vjx446a9Ys1wdZ1f+9L0yfPl0HDhyoOTk5F/x3UyIttmrVKm3atKm+8847mpGR4bq+cAP08ssvu53zzyoLFy7Ufv366YEDB1T1TKFs0qSJdu/e3TXNXujIkSN61VVXaZcuXUrlk8+lquibzptvvqnTp0/XcuXKac2aNXXu3LmuIrlr1y694oortG/fvrp9+3ar4uJvnnzySfX391cfHx9LpkpLovDNZvTo0Tpy5EhVVd2/f782aNBA77//ftd6f/31lyX5/k1BQYHOmDFD69Wrp3Xr1nVblpGRoePGjdMuXbro448/ftHOu1v0Q93x48c1Ly/P9e+dO3dq7dq1tUePHnro0CHX9U6nU7du3ep1u6HMmzfPNcNU+PiOHj1aR48ebWWsy8aqVavUz89PZ86cqQcPHiy2vKCgQNu1a6cxMTGl8vvZS9dCq1evlqFDh8qIESOkW7dubqdesdlskpeXJzNmzJD69etLlSpVrAsqIseOHZMjR47I008/LQcOHJCKFSvKsmXLJDMzU+Lj42XDhg2udatVqybXXXedbNmyRVauXCk5OTkWJv+/6f8/QlwtPlK88CCjiRMnyrhx4yQkJEQWLFgg11xzjUyePFmWLVsmx48flwYNGsgPP/wga9askXnz5lmaGf87aOLOO++UvLw8KVOmjFSsWFH+/PNPi5P93wqf84VH8B85ckQ6d+4sDodDOnXqJNddd5289tprIiKybNky2bhxo2VZ/06LnC/x3nvvlTFjxkhOTo7cd999rnUqVaoksbGx0qpVK9m6dascO3bsomQrPAAmLi5OBg4cKO3bt5fly5fL0aNHpWHDhrJu3TrZs2ePDB06VP744w8ROfP6b9mypZQpU8Yjzmd5Lv7880+ZNGmSDBgwQFJTU13bsKysLM5jeREcPnxYnnvuOZk2bZo8+uijUrVqVTl+/LgsX75cfv75ZxE587fo2bOnxMXFiUgpvM+VSjXF/+n48eN6zTXX6H/+8x9VPbP/yIkTJ3TZsmX69ddfu9YrOjxt9bfXvPHGG3rdddfpHXfcoampqap6Zl+LZs2aad++fd2mtseOHavvvfeea+TSk33//feu/7fyMXY6nXrkyBFt1qyZvvbaa27L7rnnHq1cubLOnTtXjx49qqpnDn5g30fPkZOTo5s2bdKYmBgtV66czps3z21qqZAn7HpQNMOaNWv01VdfVVXVcePGaf369bVWrVr6yCOPaH5+vqqe2cf29ttv19jYWI95zhU+toWjfCdOnNAXX3xRr776an3ggQfc1s3MzNQ//vjjoub773//q8HBwTpz5ky97bbb9IorrtBJkya5prF37typdevW1ZYtW1o+01QShw4d0jZt2mirVq107969qqo6dOhQHTdunKpygF9pys7O1tatW+urr76qeXl5+tRTT2mXLl20Ro0a6uvrqwkJCar6v33kS+P9jRJpkWPHjuk111yjixYt0v379+tTTz2l4eHh6u/vr+3atdOXX35ZVdW1EbdSYYa9e/fqY489pnXr1tVhw4a5CuIvv/yirVq10p49e+rIkSP14Ycf1kqVKnnMgUD/pvCI+ClTprius7JInjhxQps0aaLz5s1TVXWbBrvmmmu0YcOG+tprr7kdeecpb+qXm8LnyenTp4sdDDdmzBgtV66cvvXWW66yM3v2bE1OTr7oOYv6+OOPXWWq8Hlz7bXX6qxZs1T1TLHp2bOn1qpVy/UcO3XqlMbExGhISIjbfrhWWrt2rd5yyy3avXt3ffDBB127dRw7dkxffPFFbdmypUZFRV3UTH//cDBv3jz973//6/r3lClTNCQkROPi4lxFcvv27Tpo0CCvLFpOp9N1nwvPztGsWTM9dOiQRkZG6vTp01X1zDascL2LXeQvdceOHdNhw4Zp69atNSAgQPv376+zZ8/Ww4cPa58+fXT48OGl/n5GibTQDTfcoHXr1tWAgAAdNGiQvvrqq5qWlqbXX3+9Pvroo1bHc7NkyRJt0aKFDhkyRFu2bKmBgYF65513uo5w3Llzpz744IPavXt37dmzp+Vvlufq0KFD+uyzz2rlypV16tSpruut2vFeVbVnz57atWtX178Ld06/8847tWnTplqnTh3XqK/Vo9OXq8LH/dNPP9W7775br732Wp0yZYrb2Qcee+wx9ff31+joaB01apSWKVNGt23bZlVk/eGHH7Rp06Y6fPhw12j2qVOntE2bNrpgwQJVPTNqtHTpUg0LC9NatWrpgAEDtHfv3h51aq5Vq1ZphQoVdMKECfrcc89p3759tVGjRq7H9tixYzpz5kwNCQm5aAepFH0dLlmyRGfMmKGDBw8udkDk1KlTNSQkRCdPnuyazSnkbUWy8D6vXr1a58yZo7///ru2aNFC27Ztq61bt1Z/f3/t3Lmz1qlTR5s1a6bt27fXLl26FPvABTMHDhzQrVu3ugr54cOHddWqVTp//ny3x3bQoEFuZwEoLZTIi2j37t2akpLiNn26ZMkSXbJkiZ48edK1Ebnjjjt0zJgxevr0aY8oCYXnKHzttddcO9bHx8drx44d9c4773SNSBYuO9sUnifLzc3VGTNmaKVKlfSVV15xXV+aj33RUYsDBw5oenq6a6Owbds2vfLKK3XgwIFuOW6//Xb96aeftEePHtqtW7dSy4Zzs2rVKg0MDNQRI0bo1KlTtXLlynr33XfrN99841rnmWee0fDwcO3SpYtHnCZn+vTpeu211+p9993nOiNEly5ddO3ata518vPz9bffftPY2FgdNWqUTpkyRXft2mVVZDcpKSl69dVXu3b3+P3337VmzZquy9atW1X1zMF9r7zyiu7Zs6fUMxXdTkRHR7tmk2w2m0ZERBQ7Hde0adO0TJkybqOU3mrz5s1apUoVffvtt1X1zIfy7t27q81m02nTpulHH32kixYt0nfffVdXrFjxf56aDP9uxYoVWrduXb3qqqv0iiuu0DvuuEM3bdrkts7Ro0c1NjZWq1atqr/++mupZ6JEXiTLly/XOnXquEYeb775Zv3ll1/c1snIyNDY2FitXLnyRfnjn6tNmzZp9erVi41EPPfccxoQEKD33ntvsU/V3qCwyG3cuFEnTpyoISEharPZXLsSqJZOkSz6M59++mkNCwvTqlWrardu3XTmzJmqqvrJJ59ocHCwNmnSRAcOHKht27bVBg0aqKrqs88+q506dbrguaxS+Hh4wgemc7Vt2zbXrgWFrrjiCg0MDNSbb77Z7YPi0aNHLf9gVfRDy4svvqidO3fW++67T9PT07V37966fv1668IZ+Omnn3TEiBGan5+vBw4c0AYNGuiIESP022+/1UaNGmmDBg1cZf1i7HtadPTwp59+0qFDh+p3332nqqqvvPKKtmrVSqOiooqV8HfeecfrRh7/bufOnTp16lQdP368qv7vsTh06JC2a9dOO3TocMFPbH0527Bhg/r7++vMmTN1+/btOm/ePO3bt6926dLF9ZxbsWKFDh8+XGvXrn3RZg4okRfBN998owEBATpv3jxNSkrS77//XuvXr6/h4eGuad+VK1dqz549tX79+h4zbVT4pp6SkqKNGjVynfex6MavadOmWqNGDR05cqRX7pu3atUq9ff318mTJ+uzzz6rN910k1aoUEGnTZvmWqe0ys2zzz6rVapU0ZUrV+rChQs1NjZWy5Urp88++6yqnpmmGDNmjD744IP6+OOPu/ZNHTp0qA4ZMkTz8/O9qnj9k8Lp+sLnlTfcp02bNmlcXJyeOnVKDxw4oHXq1NExY8boDz/8oOXKldPIyEiPK2ZFX7cvvviidu3aVW+99VatWLGiXnvttXrTTTdp//79ddCgQRoREaGjRo1Sh8PhEQcCFVU4ujh8+HC97bbbXK+Lfv36qa+vrzZu3FhPnjxZqs+jd9991+3fS5cu1Y4dO2qPHj3cPjDMmTNH27Rpow8//PBZR3O9sUg6nU49fvy4hoaGarly5XT48OGuZYXPlcOHD2u7du00JCTEKwcYPEnh8/iZZ57Rfv36uS378ssvNSIiQkeMGKGqZz7cvvHGG64DnC4GSuRFMG3aNA0PD3ebnj58+LDWqVNHIyMjVfXMxuS11167KNMv/+afNrw9evTQVq1aueXLyMjQwYMHa1xc3FnPT+Xp/vzzT+3bt6+OHTvWdV1aWprGxcWpv79/qY5IZmVl6XXXXaevv/6667rc3Fx98803NSAgQBcvXlzsNseOHdMxY8boFVdcoSkpKRc0j1XWrl2r99xzj4aHh+u4cePcRvA8WUZGhu7YsUNPnz6tt912mw4bNsxVHq699lq12Wx6zz33uB0Y5WmmT5+uHTt21NDQUL3nnnt02rRpOmHCBH3iiSd09OjRHvMcO3z4sO7du9dtG3PixAlt166da+S+oKBAR44cqe+8847rG55Ky9y5c7Vfv35u2/NXX31V27Vrp1dccUWxWaRXXnlFw8LC9I477nA7wbg3KrodXL9+vTZo0EBbtWql3377rev6ogfbXHvttZa/p10qCmet/j6r8fLLL2u1atVcJ9m/2B/6KJEXwWOPPabt27d3/bvwjeXLL7/USpUqWbqzfVGFG4gNGzboM888o7Gxsa4dw7Ozs7V58+Z69dVX6+LFi/Xrr7/W8ePHa5s2bf7x23Y83V9//aXNmzfXxx57zO36AwcOaK9evYodtX0hZWRk6JVXXuk6xVOhzMxMHThwoOtEvYUbhNTUVJ0+fbq2bNnSI/atuxBWrlyp5cuX14kTJ+qUKVP05ptv1ooVK+r+/futjubicDhcr4ujR4/qn3/+6fo6N6fTqSdPntSuXbvqSy+95LrNgw8+qO+8845HfMVnYfYtW7bou+++qx999JFbOZw+fbrrrApWT7mfzcqVK7VDhw4aGhqqvXr10mHDhrmW3XLLLdquXTtdt26dPv7441q3bt2Lckqx9PR01whi0fJUeEDS2XZVmjZtmg4fPtzjRnXPVeHzqPB+F96PL7/8UuvUqaN33HGH23apcLk3jrR6qrfeekurVaum69evdyvz3333nTZq1Oiijj4WRYksJampqa5vGFm/fr3a7XbXEZCFvvzyS23QoIFHvWmuWLFCK1SooDfccIN269ZNfXx89M4779ScnBzNzc3V3r17a7NmzbRmzZpav359TUpKsjpyiYwbN0779OlT7NQl48ePd+3DeuzYsRKNRP7TG8fIkSN1wIABxXY2v++++7R///7F1t+/f7/XFva/O3bsmHbt2tU12nv48GENDg7Whx9+2OJkZ8yfP9/tK8JWrVqlLVq00Pbt2+uAAQNcf4fff/9dmzdvriNHjtRPP/1UY2NjNTQ01CPO+1f4nF2xYoXWqFFD27Ztq82bN9eePXvqRx995Fpv+vTp2rVrVx0yZIjrqG1P8Nlnn2n58uV19uzZunfvXp0+fbrabDbXKP1nn32mPXv21ODgYG3atKn++OOPpZ6p6Hbgiy++0KpVq2p8fLzrurffflt79OihAwcOLDaSW/SUUN6kMPfnn3+uDz/8sA4dOlSfe+4514GAn332mdapU0eHDh3qNWfl8Abbtm3TxMREt68cveWWW7RmzZr6+eefu7Yxjz32mLZo0cLtG+8uJkpkKVi1apV27txZX3nlFc3NzdXMzEwdO3as1qtXT9966y1VVdeJQVu0aOExG+59+/ZpnTp13I5Q3rBhgwYFBendd9/ttl5KSopXnfOrcEN45MgRt+muwq+dHD9+vFuZGz16tE6bNs3tfIzno+gbxm+//abfffed68PFp59+qo0aNdInn3zSNQWWnZ2t4eHhxUZHLyWnT5/W48ePa926dXXHjh168OBBDQkJcX3dnqrqBx98YNkuEvv379d69epp69at1eFwaFpamlaoUEHj4+P1mWee0W7dumlISIjroIEPP/xQq1evrg0bNryoO7Sfiy+//FKrVavmek2vWrVKK1asqA0bNnR7c5o8ebJGRER4xIEQhecffOihhzQ2NlZVz3zICA0N1UceecRtXYfDob/99ttF+XBVtED++eefmp6ermPHjtXmzZu7nR7s7bff1p49e+ott9xSrFR5w/6+Z7Ny5Ur18/PTESNG6PXXX69hYWFau3Zt1wDIZ599pg0bNtR+/fq5jpDH+Vu+fLmGhoZqhw4dNDg4WNu2bauffvqpOp1O7d+/vwYHB2ujRo00PDxcK1eubOk2hxJ5gRX9HsuiUyv79+/XJ554QsuWLatNmzbVsLAwveKKKyx/wym6USv8BoUtW7ao6v8K0FdffaW+vr66fPlySzJeKB988IE2atRIGzdurD169HDt8P3GG29os2bNtEePHnrffffpHXfcoZUrVy7xiZWLPraxsbGug5DCwsL0wQcf1JMnT+r8+fP16quv1pYtW+r111+vHTp00BYtWpTqNwxYafXq1frKK69oamqq9u3bV999912tXbu23n///a6pr3379um9997rdtqZi+nUqVP6xRdfaFhYmIaFhenq1atdBzupnjnQrFu3bhocHOw6of6OHTt0x44dpb4/nomTJ0/qQw895PpAkpaWpnXq1NGBAwfqoEGDtF69em4jkp4weqqqrkI4YMAAffHFF/X333/XWrVq6f333+96PSxbtkxXrFhx0TIVfR3GxcXp888/r6pnvoBh/Pjx2rhxY7ciuXDhQm3ZsmWpfV/xxXTkyBFt1aqV28GG27Ztc53nuPDvtXbtWm3VqpVXfMmEJ/vuu++0SpUqrpnLXbt2qc1mcxvcWb58ub700kv60ksvWb7bDCXyAkpPT9e2bdvq7NmzVfXMRvzYsWO6cuVK15F53333nT7//PP65ptvWv7HL7R06VKdN2+eHjp0SMuWLevaOJ8+fVpPnz6tf/31l7Zp00ZfeOEFi5OaK9z4Jycna/Xq1fU///mPzp8/X8PCwrRu3bquKbBPP/1UJ06cqF27dtXbb7/9gk7LzJgxQ6tXr65ffPGFqp45aXiVKlVcp2XYsGGDvvrqqzpy5EiNj493FUhvPNr93yQnJ6vdbtd33nlHVc+cD9Vms+ltt93mtt748eP16quvtmQk8u9fB9i7d28tW7ZssRGwwiIZGhrq0QeV/frrr7phwwbNysrSdu3auY7iXL16tZYrV06rVKmi77//vsUp/2fZsmXat29f3blzpz722GMaGRmpderUceV2Op2ak5Oj9913n06ZMqXUv9ErPj7etctO4XOjV69e+t5777nWSU1NdRXJokVrzZo1XrtPYOF289SpU5qRkaHVqlXTzz77zLW8oKBAk5OTXe93hY8NJxIvuddff911juDffvtN69Wr5/b897T3BUrkBeJ0OjUjI0Nbtmyp8+fPV4fDoc8884x26dJFq1Wrpna73VUirFb0U/W2bds0KChIZ86cqU6nU0eMGKEdOnRw+x5sVdXOnTu7HTzgTZKSknTVqlVuZ+/Pz8/Xa6+9VmvXru22L1V+fv4Fe2M6ffq05ubm6k033aRz585V1TPnf6xYsaLrqGyHw+E6UKMob33z+SdJSUm6fPlyjY6Odru+V69eWqdOHZ01a5a++uqr+uCDD2rFihUt37dq69atev/99+uKFSu0W7duWq9evWJvkNu3b9dWrVpp06ZNtaCgwPJR48Lfv337dv3666/ddrT/9NNPNSwszDX9+P3332uvXr30ySef9JijZ48ePaqtWrXSOXPmqOqZ8y5WrFhRGzRo4Np15vTp0xobG6tXXXVVqZ8A/ZtvvtGrr75aBwwY4JqiPXnypDZu3FiXLFnitm5qaqpGR0drs2bNin1LiLe+lpOSkvThhx/WI0eO6DXXXOPataCQ0+nUDh06uH29pNWvAW9WeMDt448/rnfccYcWFBRoSEiI2wj8O++8oy+99JJHnVuXEnkBLFiwQGfOnKkZGRk6dOhQbdu2rQYGBmr//v115syZmp6erj179nR9mrDC2Xbm3rZtmz7zzDP65JNPuq5LTEzUgQMHaps2bfSdd97Rr776SseNG6dVqlTxmJFTEydPntRGjRqpzWbTO++8021ZYZFs1KiRfvvttxfkBXm2nxEeHq5btmzRTz/9VAMCAlwnqHY4HPrGG29oYmKiR2wMSkvhG6/NZtNBgwa53deTJ0/qnXfeqR07dtQWLVroLbfc4hH7VL344ovatm1b3bx5s27cuFGbN2+u7dq1K3YE82+//eZR58FbuXKlBgQEaIMGDdRut+trr72mBQUF+vHHH2tgYKDr3JUxMTE6fPjwEu/ze6GsXbtWH3/8cR06dKhrn2HVM6N55cqV0+uvv14jIiL01ltv1SpVqly03YDee+897dWrl/bv39+1m0+LFi00ISFBVc+88Rc+n3fv3q0PPPCA3nbbbZfE63nmzJnaokUL3bx5sz7xxBPavn37YrsQDBw4UJ966il1Op2XxH22yoIFC1wHGW7cuFHr16+vFSpUKHag4cMPP6y33367R51JgRJZQunp6dqyZUt97rnnVPVMMVu+fLnOmzfP7ejOAQMG6KRJkyzJWFggDx48qO+9954uXrxYV69erXfccYdeccUVev/997utv2HDBn344YfVz89PmzZtqi1btrR8382S2L9/v3bp0kUbNGjgKsJFp2tatmypbdq0KfE5/f7+/bmFuzUMGDBAGzdurEFBQW5fdXbw4EHt0aOHzp8/v0S/1xvs379fu3btqldddZXrqNWij1dmZqbm5ORYdl7FwiyFX92pqtq1a1ft1auXqp7ZDaVNmzYaFhbmkVN2hQcrdenSRV9//XXdtWuXPv/882qz2TQ+Pl6/++47HTx4sIaEhGjHjh01ICDAVYqsdvLkSX3nnXfUZrNplSpVXCOjhX+Tn3/+WaOjo/Wuu+7SKVOmXJSvzis6G7FixQrt3r279uvXT3/66ScdMmSIfv3116qqbs/XrKwszc3N9ahRIhP/9Bro16+fnjp1SgcOHKjt27fXRx99VJctW6ZRUVEaGBjoUd+u5o0KO0Thfrbp6en64IMPar169VxfJ3n48GGNjY3VatWq6fbt262MWwwl8jwVPU9W+/bt3c4XVtSxY8dcf/zffvvtYkZU1f/l3LJli9arV0+bNWumZcuW1Xbt2mm/fv20T58+GhoaetZzD/7+++/6+++/u05i6g0KN4S//fabbt682bWxT0tLc52ipfCAp6JFsqSjSUVHen/55Rdt06aNtmnTRleuXKkpKSnaoUMHbdmypaqeedPMyMjQPn366LXXXuu1013/l3/6G4SFhRX7G3iCtWvX6p133qmffvqpqv7vKO3Cc4UmJiZqhw4dtEGDBh5TJAsfv7y8PP3rr780NjbW7fU6c+ZM9fHx0VmzZumaNWv0tdde09jYWEu2RWezbt06feyxx/SXX37R5cuXq4+Pj8bExLj2+yp8XV3M50nR1/JHH32kR48e1RUrVmivXr20W7duarPZtH79+q6D9Bo3bqyhoaFuH8Y96Xlt4myvgcIzduTl5WlMTIx27NhRGzZsqNdee+0lc85aK/y9QxTuI6+q+uOPP+rdd9+tlStX1nr16mlYWJjWqVPHIwdzKJEldM011xSbJi20YsUKveeee/Sqq66y5I9ftED6+/vrk08+qb///rt++OGHGhERoZ07d9Zp06a5Pm0Wjkw4nU6vLDaFG+6VK1dqnTp1tGnTplq+fHkdPny4pqen64EDB7R58+bavn171zdHXOiN/dixY3Xw4MHauXNnrVy5sjZu3FhfffVVXbJkiYaEhGijRo20c+fO2rlzZ23Tpo1rxMMbH+9/Y/I38AROp1NHjhzpGg2bOHGi7t27V5977jnXFLvT6dS1a9dqeHi4ZSf2PZtVq1ZpRESENmvWTJs0aVJshPHFF19UPz8/nThxokedo3DFihVavnx5ffbZZ3Xz5s2qqvrmm2+qj4+PPvfcc26vzYs1ulf058fExGiNGjVc+zO/++672rNnT23VqpXGxcXpt99+q+vWrdMPPvhA33vvPY874MHUv70GBg0a5NoH9fTp03rkyBGPmlL1Zv/UIY4cOaI//PCDTp8+XT/66COPOp90UZTI81C4ofnkk0+0c+fObt9OkJmZqTt37tQPP/xQN2/erK+++qqlO64fOHBAq1atqkOGDHG7/tVXX9VKlSrp/v37deXKlXrddddp//79PWJ/tJL49NNPtVKlSvr666+rw+HQTz75xHUEcFpamh44cEBbt26tDRo0uOBH1b711ltaqVIl/fHHH/XEiRN66NAhvf7667V79+46f/58TUtL0+eff14nTZqk8+bNcxVHb3/z+Tsr/wYm/l5IfvjhB7399tv1ueee07CwMH3ggQd0xIgR2rRpU9eZCfLz8z1mFFJVdfPmzRoYGKgPPPCADh8+XMuWLauPPvposZH1+Ph4rVSpkseck3bHjh1at25dV0Er6vXXX1cfHx99/vnnLSu9kydP1qpVq+qmTZvc9htduXKl9u3b96wnE1f1vg+DJq+BF1980aKUl55/6xAnTpzQnTt3Fjt4y1NRIktg2LBhOmDAANdo0hdffOHa/61bt26an59veUHYt2+ftm/fXvv166cbNmxwXf/ZZ59p5cqVXftXvPfee3rDDTdojx49in1ll7fIysrS+++/37Xv6d69e7V+/fp6yy23aFBQkPbr109TU1M1NTVVO3XqdMFHkyZMmKBdu3Z1nRpJ9cwUbocOHbR+/fpup1L5+9eIXSqs/huY+uKLL/TNN99U1TMjLFFRUXrvvfdqdna2zp07V0eMGKE2m01tNts/7rJild27d+szzzzj9o0pc+fO1ZCQEI2Oji5WJD1pt5R169Zpo0aN3DIWLYyF+0hOnz79omc7fvy49urVy3UqqoMHD+qXX36pI0aM0Pfee0+ff/557dOnj3bt2tUrDzb8O5PXgLd8t723+KcO0aRJE+3evbtmZ2d7/K4RlMjz9NVXX2lwcLDu2LFDly5dqvfee6/6+/vro48+qh9++KHV8dzs3LlTe/furTfccINu375dc3JytFq1am5HZaue+aaFfv36edQ0owmHw6HLli3T3bt36/Hjx7VNmzZ63333qeqZqSibzaZ9+vTRgwcPXtByX/ginzx5soaFhbl2ti/cMHz55Zfq7++vPXr0cH269PQNw/my6m9wPgoKClwHn9x11136zTffqNPp1LZt2+rkyZNV9UwpjoqK0lq1apX6KWVMZGVlaVhYmFatWrXYqVfmzJmjtWrV0gkTJriVdE96zq1cuVJDQ0NdJfL06dOufOvXr9dff/1Vly1bZslBBCdOnNCaNWvqhAkTNDExUW+77Tbt0KGDhoWFaY0aNfSNN97Qt99+Wx9++GGP2j3gfHjza8DbeVOH+DeUyPMUFxenVapU0bCwMA0JCdGnn37abaRP1bM22jt37tQ+ffpo9+7dtXLlyjpmzBjXsqJHImZnZ1sR74IpLHCLFi3STp06uQrxkiVLNDw83O2rui60rVu3apkyZTQuLs7t+rVr1+rgwYO1Z8+e2qtXL3U4HKXy+z2FlX+D87Flyxa94YYbtHPnzvroo4/qmjVrtH///rpx40bXOlZ9L+2/+emnn7Rhw4bapUsX3bZtm9uyV199Vf38/HTSpEmWl/Wz2bt3r5YvX75YAVZVHTNmjD799NOWjtLPmzdPK1eurIGBgfrkk0/qunXrVPXMCfILPxQV8vYiqeq9rwFv5m0d4p9QIs/DqVOndMSIEdqlSxcdP368ZmRkeMVpHXbu3Kk9e/bU2rVru51M/FI8x9fkyZO1RYsWrim86OhonT17dql/w8Vbb72lZcuW1XHjxmlSUpLu2bNHb7zxRn3uued0+/btarPZXG9Ilzqr/gbn4/Dhw7pw4UJt3bq1VqhQQevWrasTJkywOtb/acuWLdq6dWu9//77i+2GMm/evBJ/dWdp+u9//+t6rWzbtk23b9+uTz75pFaqVMkjThuzf/9+t8fv9OnTet11110SX2V4Nt76GvBG3tohzoYSeZ4yMzPd/vDe8ml0165d2rt3b42IiNBvvvnG6jil5qefflK73a5dunTR6667TgMDAy/aefGWL1+u1atX15CQEK1Vq5brHJSpqanasGFDjzk/X2mz8m9wvvLz8/Wxxx7TsmXLavXq1b1iZP6nn37Stm3b6ogRI856sIenOn36tC5btkwrV66sISEh2qBBA23cuLHHncYkJydHN2zYoDfddJO2bNnSI0d2LyRvfA2UhFX7ZXtrh/g7m6qqoERUVWw2m9UxztmuXbvk8ccfl2PHjslLL70kHTt2tDpSqfjuu+9k7ty5EhQUJA8++KA0b978ov3u33//XdLS0uTUqVPSpUsX8fHxkZiYGFm1apWsX79eatSocdGyWMnKv4Gpoq/jzz//XBo2bCi1a9e2ONW5+fnnn+WBBx6QevXqycSJE6VJkyZWRzpn6enpsn//frHZbFK3bl258sorrY7koqqSmJgoL7zwgpw6dUo++ugjKVu2rJw+fVrKlCljdbwLzptfA+dj/fr1ctNNN8mSJUukX79+luXwtg5RFCXyMvXbb7/J008/LS+88IJcddVVVscpNU6nU2w2m6Uv0JSUFJk6dap88skn8vnnn0vr1q0ty2IFT/gbnCtv3phv3rxZxo0bJ0uWLJHg4GCr41wyHA6HbN++XVq1aiU+Pj5SUFAgvr6+VscqNd78GjD1+++/y+TJk2Xs2LHSsGFDq+N4JUrkZSw/P1/KlStndYxLWkFBgWzbtk0WL14s99xzj0ePxMH7nTx5Uvz8/KyOcclyOp3i4+NjdQxcQJf6h4LSRokELoJTp05J2bJlrY4BAMAFQ4kEAACAMcblAQAAYIwSCQAAAGOUSAAAABijRFrA4XBIXFycOBwOq6OcF/Jby9vzi3j/fSC/tchvLfJby5Pyc2CNBbKzsyUoKEiysrIkMDDQ6jjGyG8tb88v4v33gfzWIr+1yG8tT8rPSCQAAACMUSIBAABgjNO0n4XT6ZT09HSpWLFiqXz9U3Z2ttt/vQ35reXt+UW8/z6Q31rktxb5rVXa+VVVcnJypGbNmv/nNzSxT+RZHDx4UEJDQ62OAQAAYIm0tDQJCQn513UYiTyLihUriojIjTePkrJl7RanOT9XXnWl1RFKxD/I3+oIJbJv2z6rI5RY+97trY5QImXt3v01k3m5eVZHKJHKV1a2OkKJ/LZph9URSqSc3fvf3vNyTlod4bKU7zgpb736rKsL/Rvvf5aVgsIp7LJl7V5bIsvZ/ayOUCJ2v/JWRygRb33eFOXn791FvpyXl0g9feF3pbmYyleoYHWEErF7+Ta0nJ93P/9FRE7nW53g8nYuu/NxYA0AAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgrNRLZEZGhuTm5pbq7zh58qQcPXq0VH8HAAAA/qdUSmRBQYF8/PHHMmTIEAkODpY9e/ZIfn6+REVFSXBwsPj5+Unt2rUlPj7edZsDBw5I//79JSAgQAIDA+XWW2+VP/74w7V8y5Yt0qNHD6lYsaIEBgZKu3btJCkpSURE/vjjD6lVq5YMGDBAVq5cKadOnSqNuwUAAID/74KWyG3btskTTzwhISEhcvfdd0u1atVk/fr10qpVK5k1a5asXr1ali1bJjt27JDFixdLnTp1RETE6XRK//795cSJE5KYmCjr1q2TvXv3ym233eb62UOHDpWQkBDZvHmz/PjjjxIdHS1ly5YVEZHatWvLd999J7Vr15ZRo0ZJcHCwjB49Wn788cdzyu1wOCQ7O9vtAgAAgH/mW9IfcPz4cXnnnXfk7bfflpSUFOnbt6/MnTtXbrrpJilXrpxrvQMHDkjDhg2la9euYrPZpHbt2q5lX3zxhWzbtk327dsnoaGhIiKycOFCad68uWzevFnat28vBw4ckHHjxkmTJk1ERKRhw4ZuOdq1ayft2rWTF154QdasWSMLFy6ULl26SMOGDWXYsGFy1113yZVXXnnW+xAfHy+TJk0q6UMBAABw2SjxSOTs2bNlzJgxEhAQILt375aVK1fKoEGD3AqkiMjw4cMlOTlZGjduLKNHj5bPPvvMtezXX3+V0NBQV4EUEWnWrJlUqlRJfv31VxERefzxx2XEiBHSq1cvmTJliuzZs+eseXx9feXmm2+W999/X/bt2yc1atSQcePGuU2d/11MTIxkZWW5LmlpaSV5SAAAAC55JS6R999/vzz77LNy+PBhad68udxzzz3y5ZdfitPpdFuvbdu2sm/fPnn22WclLy9Pbr31VrnlllvO+ffExcVJSkqK3HjjjfLll19Ks2bNZOXKlcXWU1X5+uuvZeTIkdK0aVPZvXu3PPPMM/L444//48+22+0SGBjodgEAAMA/K3GJrFmzpjz11FOyc+dOWbt2rZQrV04GDRoktWvXlujoaElJSXGtGxgYKLfddpu8+eabsnTpUlmxYoWcOHFCmjZtKmlpaW4jgNu3b5fMzExp1qyZ67pGjRrJY489Jp999pkMGjRI3nrrLdeynTt3ytNPPy316tWTG2+8UQoKCmTVqlWyd+9emTRpklx11VUlvasAAAD4/0q8T2RRnTt3ls6dO8vLL78sq1atkgULFsiMGTPk559/lnXr1klwcLC0adNGfHx85P3335caNWpIpUqVpFevXtKyZUsZOnSozJw5UwoKCuShhx6S7t27S1hYmOTl5cm4cePklltukbp168rBgwdl8+bNMnjwYBE5s79l06ZNJTw8XCZNmiSDBw+WChUqXMi7BgAAgCIuaIks5OfnJ5GRkRIZGSnp6ekSEBAgFStWlGnTpsmuXbukTJky0r59e/nkk0/Ex+fMYOiHH34ojzzyiHTr1k18fHykd+/eMnv2bBERKVOmjBw/flzuvvtu+eOPP6Rq1aoyaNAg18EwVatWlX379jHaCAAAcJGUSoksqmbNmiIiMnLkSBk5cuQ/rnfVVVfJhx9+eNZl5cqVkyVLlvzjbf39/SmQAAAAFxFfewgAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjvlYH8GRdBnaV8v7+Vsc4Lwd3HrQ6Qok4/nJYHaFEut1yrdURSmz7t9utjnBZs5Xx7s/4e5L3WB2hRCpfWcnqCCXi7dtQEZEKlSpYHeGy5Hvy3Lc93r2VAgAAgCUokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAx34v5yxITE2XUqFHi5+fndr3T6ZTu3bvLpk2bxOFwFLtdbm6upKSkyMyZM2XRokXi6+seOz8/XyZMmCAdO3aUPn36iL+/f7GfUbduXVm5cuWFvUMAAACXqYtaIvPy8iQyMlLi4uLcrk9NTZXo6Gix2WySnJxc7Hbh4eGiqpKRkSFz5syR8PBwt+ULFiyQnJwcOXXqlHTu3FkWLFhQ7Gd07Njxwt0RAACAyxzT2QAAADB2UUciPZXD4XCbRs/OzrYwDQAAgOdjJFJE4uPjJSgoyHUJDQ21OhIAAIBHo0SKSExMjGRlZbkuaWlpVkcCAADwaExni4jdbhe73W51DAAAAK/BSCQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwNhFPTo7KChIEhISJCEhodiyiIgIyczMlLCwsLPe1sfHR0JCQmTs2LFnXR4bGyvly5eXX3755aw/o2XLliULDwAAAJeLWiI7deokSUlJ5337qKgoiYqK+td1SvLzAQAAcG6YzgYAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwJiv1QE82dKZ88XXt6zVMc5L83YdrI5QIjXq1rA6Qoksn73Y6ggldmfMCKsjlEg5u3e+dgs58hxWRyiR4OBqVkcokS9WJFodoUQqVAqwOkKJZR/LtjpCiRTkn7I6wnnJd5w853UZiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgzNdk5cTERBk1apT4+fm5Xe90OqV79+6yadMmcTgcxW6Xm5srKSkpMnPmTFm0aJH4+rr/2vz8fJkwYYJ07NhR+vTpI/7+/sV+Rt26dWXlypUycOBA2bdvX7Hlf/31l6xZs0a+//57ee6556RcuXJuywsKCuSuu+6S8ePHm9xlAAAAnIVRiczLy5PIyEiJi4tzuz41NVWio6PFZrNJcnJysduFh4eLqkpGRobMmTNHwsPD3ZYvWLBAcnJy5NSpU9K5c2dZsGBBsZ/RsWNHERE5dOjQWX/H8OHD5dSpU5KTkyNPPvmkDB8+3G35V199JWvXrjW4twAAAPgnTGcDAADAmNFI5KXK4XC4TcNnZ2dbmAYAAMDzMRIpIvHx8RIUFOS6hIaGWh0JAADAo1EiRSQmJkaysrJcl7S0NKsjAQAAeDSms0XEbreL3W63OgYAAIDXYCQSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGDM6OjsoKAgSUhIkISEhGLLIiIiJDMzU8LCws56Wx8fHwkJCZGxY8eedXlsbKyUL19efvnll7P+jJYtW4qISNOmTf/xd5QvX16qV68uzz//vMyZM6fY8r9/FSIAAADOj1GJ7NSpkyQlJZ33L4uKipKoqKh/Xef/+vlvvfXWvy6vXbu2DBo0yDgbAAAAzh3T2QAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGPO1OoAna3VNRyln97M6xnmpUCnA6gglcrrgtNURSqR5h3ZWRyixgzsPWh2hRMrZy1odoUTyHaesjlAix34/bnWEErH7262OUCJlynj/GJF/YHmrI5SQd+Z3nDz3baf3P8sAAABw0VEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGO+Vgf4u8TERBk1apT4+fm5Xe90OqV79+6yadMmcTgcxW6Xm5srKSkpMnPmTFm0aJH4+rrftfz8fJkwYYIMHTq0VPMDAABcDjyuRObl5UlkZKTExcW5XZ+amirR0dFis9kkOTm52O3Cw8NFVSUjI0PmzJkj4eHhbssXLFggOTk5pRccAADgMsJ0NgAAAIxRIgEAAGDM46azreBwONz2s8zOzrYwDQAAgOdjJFJE4uPjJSgoyHUJDQ21OhIAAIBHo0SKSExMjGRlZbkuaWlpVkcCAADwaExni4jdbhe73W51DAAAAK/BSCQAAACMUSIBAABgjBIJAAAAY5RIAAAAGPO4A2uCgoIkISFBEhISii2LiIiQzMxMCQsLO+ttfXx8JCQkRMaOHXvW5bGxsRc0KwAAwOXK40pkp06dJCkp6bxvHxUVJVFRURcwEQAAAP6O6WwAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIz5Wh3Ak23dvFl8fctaHeO8NGvTzuoIJVKjbg2rI5RIyqYfrY5QYsMiRlkdoUR8y3n35u3PzD+tjlAitWsHWx2hRD57f73VEUrEt5x3vncVlZORa3WEy1K+4+Q5r8tIJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAY87U6wN8lJibKqFGjxM/Pz+16p9Mp3bt3l02bNonD4Sh2u9zcXElJSZGZM2fKokWLxNfX/a7l5+fLhAkTZOjQoaWaHwAA4HLgcSUyLy9PIiMjJS4uzu361NRUiY6OFpvNJsnJycVuFx4eLqoqGRkZMmfOHAkPD3dbvmDBAsnJySm94AAAAJcRprMBAABgzONGIq3gcDjcpsizs7MtTAMAAOD5GIkUkfj4eAkKCnJdQkNDrY4EAADg0SiRIhITEyNZWVmuS1pamtWRAAAAPBrT2SJit9vFbrdbHQMAAMBrMBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADDmcUdnBwUFSUJCgiQkJBRbFhERIZmZmRIWFnbW2/r4+EhISIiMHTv2rMtjY2MvaFYAAIDLlceVyE6dOklSUtJ53z4qKkqioqIuYCIAAAD8HdPZAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAY87U6gCfr2reX2P3KWx3jvKjTaXWEEjldcNrqCCXSqU8PqyOU2J7kPVZHgBc7uPOg1RFKxO5vtzpCiXj7NlREJPCKQKsjXJYcJ8ue87qMRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAw5mt1gNKQmJgoo0aNEj8/P7frnU6ndO/eXWbPnm1RMgAAgEvDJVki8/LyJDIyUuLi4tyuT01NlejoaGtCAQAAXEKYzgYAAICxS3Ik0pTD4RCHw+H6d3Z2toVpAAAAPB8jkSISHx8vQUFBrktoaKjVkQAAADwaJVJEYmJiJCsry3VJS0uzOhIAAIBHYzpbROx2u9jtdqtjAAAAeA1GIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxi7Jo7ODgoIkISFBEhISii2LiIiwIBEAAMCl5ZIskZ06dZKkpCSrYwAAAFyymM4GAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMCYr9UBPNknS5ZImTLe+RB16tHH6gglUqtBTasjlMhHC5dYHaHExs6ZZHWEEilTxrs/I+dk5lodoUQa1QmxOkKJLF/widURSqRKzSpWRyixI6l/WB3hspTvOHnO63r3VhYAAACWoEQCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxnytDmAqMTFRRo0aJX5+fm7XO51O6d69u2zatEkcDkex2+Xm5kpKSorY7faLFRUAAOCS5XUlMi8vTyIjIyUuLs7t+tTUVImOjhabzSbJycnFbhceHi6qenFCAgAAXOKYzgYAAIAxrxuJLA0Oh8NtCjw7O9vCNAAAAJ6PkUgRiY+Pl6CgINclNDTU6kgAAAAejRIpIjExMZKVleW6pKWlWR0JAADAozGdLSJ2u52jtgEAAAwwEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMOZ1R2cHBQVJQkKCJCQkFFsWEREhmZmZEhYWdtbb+vjQmQEAAC4EryuRnTp1kqSkJKtjAAAAXNYYmgMAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwJiv1QE8WcNGYVK2rN3qGOelYuUAqyOUSL7jlNURSqR+g1ZWRyixQ3vSrY5QIrYy3v0ZuSC/wOoIJbLtL4fVEUrEt5x3vz16+/NHRMQvoLzVES5LtrK2c17Xu7eyAAAAsAQlEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADDma3WAv0tMTJRRo0aJn5+f2/VOp1O6d+8umzZtEofDUex2ubm5kpKSIjNnzpRFixaJr6/7XcvPz5cJEybI0KFDSzU/AADA5cDjSmReXp5ERkZKXFyc2/WpqakSHR0tNptNkpOTi90uPDxcVFUyMjJkzpw5Eh4e7rZ8wYIFkpOTU3rBAQAALiNMZwMAAMCYx41EWsHhcLhNkWdnZ1uYBgAAwPMxEiki8fHxEhQU5LqEhoZaHQkAAMCjUSJFJCYmRrKyslyXtLQ0qyMBAAB4NKazRcRut4vdbrc6BgAAgNdgJBIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYMzjjs4OCgqShIQESUhIKLYsIiJCMjMzJSws7Ky39fHxkZCQEBk7duxZl8fGxl7QrAAAAJcrjyuRnTp1kqSkpPO+fVRUlERFRV3ARAAAAPg7prMBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADDma3UAT7Zu3dtis9msjnFeBpSPsjpCiTS+prHVEUok8atlVkcosUeeHWF1hBKpYLdbHaFEjmRnWx2hRLo0amR1hBKJ+W671RFKpFpoNasjlNjhfYetjlAi6nRaHeG85OefPOd1GYkEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYMzX6gCmEhMTZdSoUeLn5+d2vdPplO7du8umTZvE4XAUu11ubq6kpKSI3W6/WFEBAAAuWV5XIvPy8iQyMlLi4uLcrk9NTZXo6Gix2WySnJxc7Hbh4eGiqhcnJAAAwCWO6WwAAAAY87qRyNLgcDjcpsCzs7MtTAMAAOD5GIkUkfj4eAkKCnJdQkNDrY4EAADg0SiRIhITEyNZWVmuS1pamtWRAAAAPBrT2SJit9s5ahsAAMAAI5EAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGNed3R2UFCQJCQkSEJCQrFlERERkpmZKWFhYWe9rY8PnRkAAOBC8LoS2alTJ0lKSrI6BgAAwGWNoTkAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIz5Wh3Akzkcf1od4bydPn3a6giXtb/ysq2OUGJ+ZctaHaFEKtjtVkcoEW9//APLl7c6QomUKVPG6gglok6n1REue6cLvPNvcLpAz3ldRiIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGPO1OsDfJSYmyqhRo8TPz8/teqfTKd27d5dNmzaJw+Eodrvc3FxJSUmRmTNnyqJFi8TX1/2u5efny4QJE2To0KGlmh8AAOBy4HElMi8vTyIjIyUuLs7t+tTUVImOjhabzSbJycnFbhceHi6qKhkZGTJnzhwJDw93W75gwQLJyckpveAAAACXEaazAQAAYMzjRiKt4HA43KbIs7OzLUwDAADg+RiJFJH4+HgJCgpyXUJDQ62OBAAA4NEokSISExMjWVlZrktaWprVkQAAADwa09kiYrfbxW63Wx0DAADAazASCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAw5nFHZwcFBUlCQoIkJCQUWxYRESGZmZkSFhZ21tv6+PhISEiIjB079qzLY2NjL2hWAACAy5XHlchOnTpJUlLSed8+KipKoqKiLmAiAAAA/B3T2QAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGPO1OoAnqxlcX3x8ylgd47zYy9utjlAietppdYQSqVbtKqsjlNjx3FyrI5TInw6H1RFK5Eh2ttURSmT3H39YHeGylu84ZXWEEivj653vv4XU6Z3vY2WctnNel5FIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMZ8rQ7wd4mJiTJq1Cjx8/Nzu97pdEr37t1l06ZN4nA4it0uNzdXUlJSZObMmbJo0SLx9XW/a/n5+TJhwgQZOnRoqeYHAAC4HHhciczLy5PIyEiJi4tzuz41NVWio6PFZrNJcnJysduFh4eLqkpGRobMmTNHwsPD3ZYvWLBAcnJySi84AADAZYTpbAAAABjzuJFIKzgcDrcp8uzsbAvTAAAAeD5GIkUkPj5egoKCXJfQ0FCrIwEAAHg0SqSIxMTESFZWluuSlpZmdSQAAACPxnS2iNjtdrHb7VbHAAAA8BqMRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjHnc0dlBQUGSkJAgCQkJxZZFRERIZmamhIWFnfW2Pj4+EhISImPHjj3r8tjY2AuaFQAA4HLlcSWyU6dOkpSUdN63j4qKkqioqAuYCAAAAH/HdDYAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMZ8rQ7gyV5f9a5UCAiwOsZ52fzDL1ZHKJGjaUetjlAic1ctsjpCic3/j3ffh/z8fKsjlIh/QAWrI5TIm3/8bnWEEulyY7jVEUrkz8w/rY5QYiGNQqyOcFk6mZd3zusyEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAmK/VAUpDYmKijBo1Svz8/Nyudzqd0r17d5k9e7ZFyQAAAC4Nl2SJzMvLk8jISImLi3O7PjU1VaKjo60JBQAAcAlhOhsAAADGKJEAAAAwdklOZ5tyOBzicDhc/87OzrYwDQAAgOdjJFJE4uPjJSgoyHUJDQ21OhIAAIBHo0SKSExMjGRlZbkuaWlpVkcCAADwaExni4jdbhe73W51DAAAAK/BSCQAAACMUSIBAABgjBIJAAAAY5RIAAAAGLskD6wJCgqShIQESUhIKLYsIiLCgkQAAACXlkuyRHbq1EmSkpKsjgEAAHDJYjobAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjlEgAAAAYo0QCAADAGCUSAAAAxiiRAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjvlYH8GSfvP+l2O1+Vsc4L3Z/u9URSsS3nHc/NT97f73VEUqs8TVNrI5wWTtdcNrqCCVSv019qyOUiCPPYXWEEvH2baiIyJ9ZuVZHuCw5Tuad87qMRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMV+rA/xdYmKijBo1Svz8/Nyudzqd0r17d9m0aZM4HI5it8vNzZWUlBSZOXOmLFq0SHx93e9afn6+TJgwQYYOHVqq+QEAAC4HHlci8/LyJDIyUuLi4tyuT01NlejoaLHZbJKcnFzsduHh4aKqkpGRIXPmzJHw8HC35QsWLJCcnJzSCw4AAHAZYTobAAAAxjxuJNIKDofDbYo8OzvbwjQAAACej5FIEYmPj5egoCDXJTQ01OpIAAAAHo0SKSIxMTGSlZXluqSlpVkdCQAAwKMxnS0idrtd7Ha71TEAAAC8BiORAAAAMEaJBAAAgDFKJAAAAIxRIgEAAGCMEgkAAABjHnd0dlBQkCQkJEhCQkKxZREREZKZmSlhYWFnva2Pj4+EhITI2LFjz7o8Njb2gmYFAAC4XHlciezUqZMkJSWd9+2joqIkKirqAiYCAADA3zGdDQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOUSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMV+rA3gyvwp+Yvcrb3UMeCG/AO9/3pwuOG11BHgxb3/+2HwYY7EafwNrmDzu/IUAAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGPO1OkBpSExMlFGjRomfn5/b9U6nU7p37y6zZ8+2KBkAAMCl4ZIskXl5eRIZGSlxcXFu16empkp0dLQ1oQAAAC4hTGcDAADA2CU5EmnK4XCIw+Fw/Ts7O9vCNAAAAJ6PkUgRiY+Pl6CgINclNDTU6kgAAAAejRIpIjExMZKVleW6pKWlWR0JAADAozGdLSJ2u13sdrvVMQAAALwGI5EAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGOX5NHZQUFBkpCQIAkJCcWWRUREWJAIAADg0nJJlshOnTpJUlKS1TEAAAAuWUxnAwAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgzNfqAJ5sxVtvio9PGatjnJeevW+xOkKJhDQKsTpCiSx/879WRyix5xbNsjpCifj6ePdn5Oy/8qyOUCKtal9ldYQSeX3OMqsjlEi10GpWRyixQ3vSrY5QIqdPO62OcF7yHSfPeV3v3soCAADAEpRIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMZKrURmZGRIbm5uaf14NwcOHLgovwcAAABnXNASWVBQIB9//LEMGTJEgoODZc+ePSIikpaWJrfeeqtUqlRJqlSpIv3795fU1FTX7ZxOp0yePFlCQkLEbrdL69atZe3ata7l+fn5EhUVJcHBweLn5ye1a9eW+Ph41/Jhw4ZJixYtZPr06XLo0KELeZcAAABwFhekRG7btk2eeOIJCQkJkbvvvluqVasm69evl1atWsmpU6ckIiJCKlasKBs2bJCNGzdKQECA9O7dW/Lz80VE5OWXX5YXXnhBZsyYIVu3bpWIiAjp16+f7Nq1S0REZs2aJatXr5Zly5bJjh07ZPHixVKnTh3X71+2bJncf//9snTpUgkNDZW+ffvK0qVL5eTJk+eU3+FwSHZ2ttsFAAAA/+y8S+Tx48fl5ZdflrZt20pYWJjs3btX5s6dK4cOHZK5c+dKp06dRERk6dKl4nQ6Zd68edKyZUtp2rSpvPXWW3LgwAH56quvRERkxowZMn78eImMjJTGjRvL1KlTpXXr1jJz5kwROTNd3bBhQ+natavUrl1bunbtKrfffrsrS7Vq1WT06NGSlJQk27Ztk6uvvlrGjh0rwcHB8sADD8j333//r/clPj5egoKCXJfQ0NDzfVgAAAAuC+ddImfPni1jxoyRgIAA2b17t6xcuVIGDRok5cqVc1tvy5Ytsnv3bqlYsaIEBARIQECAVKlSRU6ePCl79uyR7OxsSU9Ply5durjdrkuXLvLrr7+KiMjw4cMlOTlZGjduLKNHj5bPPvvsH3M1bdpUpkyZIvv375fo6GiZP3++9O7d+1/vS0xMjGRlZbkuaWlp5/moAAAAXB58z/eG999/v/j6+srChQulefPmMnjwYLnrrrskPDxcfHz+101zc3OlXbt2snjx4mI/o1q1auf0u9q2bSv79u2TNWvWyOeffy633nqr9OrVS5YvX15s3bS0NFm8eLEsWrRI9u3bJ0OGDJF77rnnX3++3W4Xu91+TlkAAABQgpHImjVrylNPPSU7d+6UtWvXSrly5WTQoEFSu3ZtiY6OlpSUFBE5UwB37dol1atXlwYNGrhdgoKCJDAwUGrWrCkbN250+/kbN26UZs2auf4dGBgot912m7z55puydOlSWbFihZw4cUJERHJycmTBggXSs2dPqVOnjnz88cfy+OOPy+HDh2Xx4sXSq1ev872bAAAAOIsLcmBN586d5fXXX5fDhw/L9OnTJTk5WVq1aiXbtm2ToUOHStWqVaV///6yYcMG2bdvn3z11VcyevRoOXjwoIiIjBs3TqZOnSpLly6VHTt2SHR0tCQnJ8ujjz4qIiIvvviiLFmyRH777TfZuXOnvP/++1KjRg2pVKmSiIgMGDBAJk2aJF27dpWdO3fKhg0b5L777pPAwMALcfcAAADwN+c9nX02fn5+EhkZKZGRkZKeni4BAQHi7+8vX3/9tYwfP14GDRokOTk5UqtWLbnuuutcJW/06NGSlZUlTzzxhBw5ckSaNWsmq1evloYNG4qISMWKFWXatGmya9cuKVOmjLRv314++eQT17T53LlzpVGjRmKz2S7k3QEAAMA/uKAlsqiaNWu6/r9GjRry9ttv/+O6Pj4+MnHiRJk4ceJZl48cOVJGjhz5j7dv3Ljx+QcFAACAMb72EAAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMZ8rQ7gyXx9y4mPTxmrY8AL+ZYtZ3WEEnOcOmV1hBIp8PHuz8gF+d79+P/pcFgd4bLm7c8feAfv3soCAADAEpRIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMZKrURmZGRIbm5uaf14NwcOHLgovwcAAABnXNASWVBQIB9//LEMGTJEgoODZc+ePSIikpaWJrfeeqtUqlRJqlSpIv3795fU1FTX7ZxOp0yePFlCQkLEbrdL69atZe3ata7l+fn5EhUVJcHBweLn5ye1a9eW+Ph41/Jhw4ZJixYtZPr06XLo0KELeZcAAABwFhekRG7btk2eeOIJCQkJkbvvvluqVasm69evl1atWsmpU6ckIiJCKlasKBs2bJCNGzdKQECA9O7dW/Lz80VE5OWXX5YXXnhBZsyYIVu3bpWIiAjp16+f7Nq1S0REZs2aJatXr5Zly5bJjh07ZPHixVKnTh3X71+2bJncf//9snTpUgkNDZW+ffvK0qVL5eTJk+eU3+FwSHZ2ttsFAAAA/+y8S+Tx48fl5ZdflrZt20pYWJjs3btX5s6dK4cOHZK5c+dKp06dRERk6dKl4nQ6Zd68edKyZUtp2rSpvPXWW3LgwAH56quvRERkxowZMn78eImMjJTGjRvL1KlTpXXr1jJz5kwROTNd3bBhQ+natavUrl1bunbtKrfffrsrS7Vq1WT06NGSlJQk27Ztk6uvvlrGjh0rwcHB8sADD8j333//r/clPj5egoKCXJfQ0NDzfVgAAAAuC+ddImfPni1jxoyRgIAA2b17t6xcuVIGDRok5cqVc1tvy5Ytsnv3bqlYsaIEBARIQECAVKlSRU6ePCl79uyR7OxsSU9Ply5durjdrkuXLvLrr7+KiMjw4cMlOTlZGjduLKNHj5bPPvvsH3M1bdpUpkyZIvv375fo6GiZP3++9O7d+1/vS0xMjGRlZbkuaWlp5/moAAAAXB58z/eG999/v/j6+srChQulefPmMnjwYLnrrrskPDxcfHz+101zc3OlXbt2snjx4mI/o1q1auf0u9q2bSv79u2TNWvWyOeffy633nqr9OrVS5YvX15s3bS0NFm8eLEsWrRI9u3bJ0OGDJF77rnnX3++3W4Xu91+TlkAAABQgpHImjVrylNPPSU7d+6UtWvXSrly5WTQoEFSu3ZtiY6OlpSUFBE5UwB37dol1atXlwYNGrhdgoKCJDAwUGrWrCkbN250+/kbN26UZs2auf4dGBgot912m7z55puydOlSWbFihZw4cUJERHJycmTBggXSs2dPqVOnjnz88cfy+OOPy+HDh2Xx4sXSq1ev872bAAAAOIsLcmBN586d5fXXX5fDhw/L9OnTJTk5WVq1aiXbtm2ToUOHStWqVaV///6yYcMG2bdvn3z11VcyevRoOXjwoIiIjBs3TqZOnSpLly6VHTt2SHR0tCQnJ8ujjz4qIiIvvviiLFmyRH777TfZuXOnvP/++1KjRg2pVKmSiIgMGDBAJk2aJF27dpWdO3fKhg0b5L777pPAwMALcfcAAADwN+c9nX02fn5+EhkZKZGRkZKeni4BAQHi7+8vX3/9tYwfP14GDRokOTk5UqtWLbnuuutcJW/06NGSlZUlTzzxhBw5ckSaNWsmq1evloYNG4qISMWKFWXatGmya9cuKVOmjLRv314++eQT17T53LlzpVGjRmKz2S7k3QEAAMA/uKAlsqiaNWu6/r9GjRry9ttv/+O6Pj4+MnHiRJk4ceJZl48cOVJGjhz5j7dv3Ljx+QcFAACAMb72EAAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwBglEgAAAMYokQAAADBGiQQAAIAxSiQAAACMUSIBAABgjBIJAAAAY5RIAAAAGKNEAgAAwJiv1QE8kaqKiIjTedriJOcvP/+k1RFKxHEyz+oIJXL6dIHVEUrsrz//tDpCiZSx2ayOUCJ5f3n3azg3J8fqCCWS7/Dux9/bt6Ei3v83OH3aaXWE85Kf7xCR/3Whf2PTc1nrMnPw4EEJDQ21OgYAAIAl0tLSJCQk5F/XoUSehdPplPT0dKlYsaLYSmE0Izs7W0JDQyUtLU0CAwMv+M8vbeS3lrfnF/H++0B+a5HfWuS3VmnnV1XJycmRmjVrio/Pv+/1yHT2Wfj4+Pyf7ftCCAwM9MoncCHyW8vb84t4/30gv7XIby3yW6s08wcFBZ3TehxYAwAAAGOUSAAAABijRFrAbrfLxIkTxW63Wx3lvJDfWt6eX8T77wP5rUV+a5HfWp6UnwNrAAAAYIyRSAAAABijRAIAAMAYJRIAAADGKJEAAAAwRokEAACAMUokAAAAjFEiAQAAYIwSCQAAAGP/D7oO7zzYAY3cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
