{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation + Transformer\n",
    "\n",
    "English-Myanmar Translation using Transformers\n",
    "\n",
    "Training for Additive Attention\n",
    "\n",
    "Maung Maung Kyi Tha : st125214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install numpy==1.26.4\\n!pip3 install torch==2.2.0\\n!pip3 install torchdata\\n!pip3 install torchtext==0.16.2\\n!pip3 install portalocker\\n!pip3 install datasets\\n!pip3 install spacy\\n!pip3 install matplotlib\\n!python3 -m spacy download en_core_web_sm\\n!pip3 install pyidaungsu\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# to be run only first time, if you haven't installed libraries\n",
    "'''\n",
    "!pip install numpy==1.26.4\n",
    "!pip3 install torch==2.2.0\n",
    "!pip3 install torchdata\n",
    "!pip3 install torchtext==0.16.2\n",
    "!pip3 install portalocker\n",
    "!pip3 install datasets\n",
    "!pip3 install spacy\n",
    "!pip3 install matplotlib\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!pip3 install pyidaungsu\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Loading libraries\n",
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random, math, time\n",
    "import numpy\n",
    "\n",
    "# setting device to GPU cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Seet my seed\n",
    "SEED = 69\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Making sure we get the same results on each run\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Disable user warnings for neater output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using GPU device : NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "My torch library version : 2.2.0+cu118\n",
      "My torchtext library version : 0.16.2+cpu\n"
     ]
    }
   ],
   "source": [
    "# What is my device, and cuda versions\n",
    "print(f\"I am using GPU device : {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"My torch library version : {torch.__version__}\")\n",
    "print(f\"My torchtext library version : {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  2 20:54:34 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.14                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   40C    P0             16W /  140W |    5610MiB /   6141MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6596    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      7000    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      7792    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      8944    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      9492      C   ...0_x64__qbz5n2kfra8p0\\python3.12.exe      N/A      |\n",
      "|    0   N/A  N/A      9644    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      9660    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     10640    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     11232    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     11332    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11424    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12860    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13072    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14780    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18044    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     19776    C+G   ...n\\132.0.2957.127\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19868    C+G   ...2.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     21428    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     22184      C   ...0_x64__qbz5n2kfra8p0\\python3.12.exe      N/A      |\n",
      "|    0   N/A  N/A     23840    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     23864    C+G   ...5.9.2.0_x64__htrsf667h5kn2\\AWCC.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Checking detailed GPU info\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset\n",
    "\n",
    "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English-myanmar parallel dataset from torchtext.datasets \n",
    "import torchtext, datasets\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TRG_LANGUAGE = 'mm'\n",
    "\n",
    "# I've experimented with two different english-myanmar parallel datasets here\n",
    "\n",
    "# Import parallel dataset by Aung Kaung Htet\n",
    "dataset = datasets.load_dataset('akhtet/myanmar-xnli')\n",
    "\n",
    "# Import parallel dataset uploaded from Christan bible translation\n",
    "#dataset = datasets.load_dataset('st125338/en_my_nlp_a3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['genre', 'label', 'sentence1_en', 'sentence2_en', 'sentence1_my', 'sentence2_my'],\n",
       "        num_rows: 5010\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking structure of parallel dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing for Christan bible translation\n",
    "# train = [(row['en'], row['my']) for row in dataset['train']]\n",
    "# val = [(row['en'], row['my']) for row in dataset['validation']]\n",
    "# test = [(row['en'], row['my']) for row in dataset['test']]\n",
    "\n",
    "# Processing for parallel dataset by Aung Kaung Htet\n",
    "# since this dataset has two separate parallel sets, we will choose second set\n",
    "train = [(row['sentence2_en'], row['sentence2_my']) for row in dataset['train']]\n",
    "val = [(row['sentence2_en'], row['sentence2_my']) for row in dataset['validation']]\n",
    "test =  [(row['sentence2_en'], row['sentence2_my']) for row in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Product and geography are what make cream skimming work. ', 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။'), ('You lose the things to the following level if the people recall.', 'လူတွေပြန်ခေါ်ရင် အောက်ပါအဆင့်အထိ ဆုံးရှုံးသွားမယ်။'), ('A member of my team will execute your orders with immense precision.', 'ကျွန်ုပ်၏အဖွဲ့သားတစ်ဦးသည် သင်၏အမိန့်စာများကို အလွန်တိကျစွာ ဆောင်ရွက်ပေးပါမည်။'), ('This information belongs to them.', 'ဒီအချက်အလက်က သူတို့ပိုင်တယ်။'), ('The tennis shoes have a range of prices.', 'တင်းနစ်ဖိနပ်များသည် ဈေးနှုန်းအမျိုးမျိုးရှိသည်။'), (\"I'm upset that my walkman broke and now I have to turn the stereo up really loud.\", 'ကျွန်တော့်ရဲ့ လမ်းလျှောက်သမား ပြတ်သွားလို့ စိတ်မကောင်းဖြစ်ပြီး အခု စတီရီယိုကို တကယ် အသံကျယ်အောင် ပြန်ဖွင့်ရမှာ ဖြစ်ပါတယ်။'), ('Most of the Christian mosaics were destroyed by Muslims.  ', 'ခရစ်ယာန် ဗလီစာ အများစုကို မူဆလင်များက ဖျက်ဆီးခဲ့သည်။'), (\"Slate had an opinion on Jackson's findings.\", 'Slate သည် Jackson ၏တွေ့ရှိချက်အပေါ်အမြင်တစ်ခုရှိသည်။'), ('Heterosexuals.', 'ကဿာမိ။'), ('Place des Vosges is constructed entirely of gray marble.', 'Place des Vosges ကို မီးခိုးရောင် စကျင်ကျောက်ဖြင့် လုံး၀ တည်ဆောက်ထားသည်။')]\n",
      "[('He called his mom as soon as the school bus dropped him off.', 'ကျောင်းကားက သူ့ကို ချပေးပြီးပြီးချင်း သူက သူ့အမေကို ခေါ်ခဲ့တယ်။'), (\"He didn't say a word.\", 'သူ စကားတစ်လုံးမပြောခဲ့ဘူး။'), ('He told his mom he had gotten home.', 'သူ အိမ်ပြန်ရောက်ပြီလို့ သူ့အမေကို ပြောခဲ့တယ်။'), ('I have never been to Washington so when I was assigned there I got lost trying to find the place.', 'ဝါရှင်တန်ကို ကျွန်တော် တစ်ခါမှမရောက်ဖူးတာကြောင့် ကျွန်တော့်ကို အဲ့ဒီကို တာဝန်ပေးခံရ သောအခါ နေရာရှာရင်းနဲ့ လမ်းပျောက်ခဲ့တယ်။'), ('I knew exactly what I needed to do as I marched to Washington.', 'ဝါရှင်တန်ကို ငါချီတက်ခဲ့တာနဲ့ ငါ ဘာလုပ်ဖို့ လိုခဲ့လိုဆိုတာကို ငါအတိအကျ သိခဲ့တယ်။'), ('I was not quite certain what I was going to do so I went to Washington where I was assigned to report.', 'ငါ ဘာလုပ်ရမယ်ဆိုတာ ငါတော်တော် မသေချာခဲ့ဘူး ဒါကြောင့် ငါ တာဝန်ပေးခံရတဲ့ ဝါရှင်တန်ကို သတင်းပို့ဖို့ သွားခဲ့တယ်။'), ('He was the first to be invited and enjoyed the experience.', 'သူဟာ ပထမဆုံးဖိတ်ခံခဲ့ရပြီး အတွေ့အကြုံကို ခံစားပျော်ရွှင်ခဲ့တယ်။'), (\"He wasn't allowed to attend.\", 'သူ တက်ရောက်ခွင့်မရခဲ့ဘူး။'), (\"He wasn't allowed to go to the museum's opening.\", 'သူ့ကို ပြတိုက်ဖွင့်ပွဲ သွားဖို့ ခွင့်မပြုခဲ့ဘူး။'), ('After I said yes, it ended.', 'ငါ အင်း လို့ ပြောပြီးနောက် ၊ အဲ့ဒါ ပြီးသွားခဲ့တယ်။')]\n",
      "[('I havent spoken to him again.', 'ငါ သူ့ကို စကား ထပ်မပြောဖြစ်ဘူး။'), ('I was so upset that I just started talking to him again.', 'ငါ အရမ်းစိတ်မကောင်းဖြစ်လို့ သူကို တဖန် စကားစပြောရုံပါပဲ။'), ('We had a great talk.', 'ငါတို့ စကားကောင်းခဲ့တယ်။'), ('I was not aware that I was not the only person to be at the field that day.', 'အဲ့ဒီနေ့က ကွင်းထဲမှာ ရှိတဲ့သူက ကျွန်တော်တစ်ယောက်ထဲပဲမဟုတ်လို့ ကျွန်တော် သတိမထားမိခဲ့ဘူး။'), ('I was under the impression that I was the only one with that number at the AFFC Air Force Career field.', 'ကျွန်တော် က အေအက်ဖ်အက်ဖ်စီ လေတပ် အသက်မွေးဝမ်းကြောင်း လုပ်ငန်း မှာ အဲလို နံပါတ်နဲ့ တစ်ယောက်တည်းသောသူ လို့ ကျွန်တော် ထင်မြင်ခဲ့တယ်။'), ('We all were given the same exact number no matter what privileges we were promised to be granted, it was all a lie.', 'အခွင့်ထူးတွေ ခွင့်ပြုပေးဖို့ ကျွန်တော်တို့ကို ကတိပေးထားခဲ့ပေမယ့် ကျွန်တော်တို့အားလုံး အတိအကျ တူညီတဲ့ အရေအတွက်တွေ ပေးခြင်းခံရတယ်၊ ဒါတွေ အားလုံးက အလိမ်အညာပဲ။'), ('I was never told anything about meeting anyone.', 'တယောက်ယောက်နဲ့ တွေ့ဖို့အကြောင်း ငါ ဘယ်တုန်းကမှ အပြောမခံခဲ့ရဘူး။'), ('I was told a guy would be called in for me to meet.', 'ငါ့တွေ့ဖို့ ယောက်ျားလေးတစ်ယောက်ကို ခေါ်သွင်း လိမ့်မယ်လို့ ငါ့ကိုပြောခဲ့တယ်။'), ('The guy showed up a bit late.', 'အဲ့ဒီ ယောက်ျားလေးဟာ အနည်းငယ် နောက်ကျပြီးမှ ရောက်လာခဲ့တယ်။'), ('I want to tell you everything I know about that!', 'အဲ့ဒါနဲ့ ပတ်သက်ပြီး ငါ သိသမျှကို မင်းကို ပြောပြချင်တယ်!')]\n"
     ]
    }
   ],
   "source": [
    "#so this is a datapipe object; very similar to pytorch dataset version 2 which is better\n",
    "print(train[0:10])\n",
    "print(val[0:10])\n",
    "print(test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Product and geography are what make cream skimming work. ',\n",
       " 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking What does it looks like\n",
    "sample = next(iter(train))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of training dataset\n",
    "train_size_all = len(list(iter(train)))\n",
    "train_size_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_part1 : 137445\n"
     ]
    }
   ],
   "source": [
    "# Since The size is too much (400,000 lines), I will reduce the train size into 35% of original,\n",
    "# and then split again into train, val and test datasets\n",
    "# I will not use random split, but just split by index to make the train set consistent between the three model experimentations\n",
    "\n",
    "# Define the split ratio\n",
    "split_ratio = 0.35\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(train) * split_ratio)\n",
    "\n",
    "# Divide the train dataset into two parts\n",
    "train_part1 = train[:split_index]\n",
    "print(f'size of train_part1 : {len(train_part1)}')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "generator = torch.Generator().manual_seed(69)\n",
    "\n",
    "# Now splitting again\n",
    "train_size_all = len(list(iter(train_part1)))\n",
    "train_size = int(0.7 * train_size_all)\n",
    "val_size = int(0.2 * train_size_all)\n",
    "test_size = train_size_all - (train_size + val_size)  # Ensure all data is included\n",
    "\n",
    "# Perform the split again for final train, val and test\n",
    "train, val, test = torch.utils.data.random_split(train_part1, [train_size, val_size, test_size], generator)\n",
    "\n",
    "# after this, newly sized train, val and test will be used for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96211"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final training\n",
    "train_size = len(list(iter(train)))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27489"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final validation\n",
    "val_size = len(list(iter(val)))\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13745"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of final test\n",
    "test_size = len(list(iter(test)))\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n",
    "\n",
    "**Note**: the models must first be downloaded using the following on the command line: \n",
    "```\n",
    "python3 -m spacy download en_core_web_sm\n",
    "```\n",
    "For myanmar tokenizing, we will use a custom tokenizer with PyICU\n",
    "\n",
    "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myanmar word tokenizer with PyICU\n",
    "from icu import BreakIterator, Locale\n",
    "\n",
    "def pyicu_tokenizer(sentence):\n",
    "    bi = BreakIterator.createWordInstance(Locale(TRG_LANGUAGE))\n",
    "    bi.setText(sentence)\n",
    "    tokens = []\n",
    "    start = bi.first()\n",
    "    for end in bi:\n",
    "        token = sentence[start:end].strip()  # remove leading/trailing spaces\n",
    "        if token:  # only add non-empty tokens\n",
    "            tokens.append(token)\n",
    "        start = end\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': functools.partial(<function _spacy_tokenize at 0x000001BB529B4040>, spacy=<spacy.lang.en.English object at 0x000001BB78B3A990>),\n",
       " 'mm': <function __main__.pyicu_tokenizer(sentence)>}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining english and myanmar word tokenizers\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TRG_LANGUAGE] = pyicu_tokenizer\n",
    "token_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Product and geography are what make cream skimming work. \n",
      "Tokenization:  ['Product', 'and', 'geography', 'are', 'what', 'make', 'cream', 'skimming', 'work', '.'] ['ထုတ်ကုန်နှင့်', 'ပထဝီဝင်အနေအထားသည်', 'ခရင်မ်', 'skimming', 'ကို', 'အလုပ်ဖြစ်စေသည်။']\n",
      "('Product and geography are what make cream skimming work. ', 'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။')\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "print(\"Sentence: \", sample[0])\n",
    "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]), token_transform[SRC_LANGUAGE](sample[1]))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text to integers (Numericalization)\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
    "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 10, 9, 0, 9]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see some example\n",
    "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marriage'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
    "\n",
    "#print 1816, for example\n",
    "mapping[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try unknown vocab\n",
    "mapping[0]\n",
    "#they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24533"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n",
    "\n",
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# reduce batch size to avoid GPU memory error\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# reduce batch size to avoid GPU memory error\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, mm in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([32, 24])\n",
      "Myanmar shape:  torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
    "print(\"Myanmar shape: \", mm.shape)   # (batch_size, seq len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model\n",
    "\n",
    "<img src=\"../figures/transformer-encoder.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        _src    = self.feedforward(src)\n",
    "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                           for _ in range(n_layers)])\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len    = src.shape[1]\n",
    "        \n",
    "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, src_len]\n",
    "        \n",
    "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutli Head Attention Layer\n",
    "\n",
    "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive Attention (Bahdanau Attention)\n",
    "\n",
    "Formula:\n",
    "\n",
    "<img src = \"figures/Additive Formula.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim  = hid_dim\n",
    "        self.n_heads  = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        #Additional linear layers for additive attention\n",
    "        self.w1 = nn.Linear(self.head_dim, self.head_dim)\n",
    "        self.w2 = nn.Linear(self.head_dim, self.head_dim)\n",
    "        self.vt = nn.Linear(self.head_dim, 1)\n",
    "        \n",
    "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "                \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        #src, src, src, src_mask\n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        #Q=K=V: [batch_size, src len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        #Q = [batch_size, n heads, query len, head_dim]\n",
    "        \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
    "        #energy = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        # Additional code for Additive Attention layer\n",
    "        q_len = query.shape[1]\n",
    "        qw1 = self.w1(Q).view(batch_size, self.n_heads, q_len, 1, self.head_dim)\n",
    "\n",
    "        k_len = key.shape[1]\n",
    "        kw2 = self.w2(K).view(batch_size, self.n_heads, 1, k_len, self.head_dim)\n",
    "\n",
    "        energy = torch.tanh(qw1 + kw2)\n",
    "        # energy = self.vt(energy).view(batch_size, self.n_heads, q_len, k_len @ self.n_heads, 1)\n",
    "        energy = self.vt(energy).squeeze(-1)\n",
    "\n",
    "        #for making attention to padding to 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        #attention = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
    "        #x = [batch_size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
    "        #x = [batch_size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        return x, attention\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [batch size, src len, hid dim]\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder Layer\n",
    "\n",
    "<img src = \"../figures/transformer-decoder.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        #attention = [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        _trg = self.feedforward(trg)\n",
    "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
    "                 pf_dim, dropout, device,max_length = 100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                            for _ in range(n_layers)])\n",
    "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len    = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, trg len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            \n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        #attention: [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        #output = [batch_size, trg len, output_dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together (become Seq2Seq!)\n",
    "\n",
    "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 1\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
    "OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(24533, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(14410, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=14410, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
    "hid_dim = 256\n",
    "enc_layers = 3\n",
    "dec_layers = 3\n",
    "enc_heads = 8\n",
    "dec_heads = 8\n",
    "enc_pf_dim = 512\n",
    "dec_pf_dim = 512\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX\n",
    "\n",
    "enc = Encoder(input_dim, \n",
    "              hid_dim, \n",
    "              enc_layers, \n",
    "              enc_heads, \n",
    "              enc_pf_dim, \n",
    "              enc_dropout, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(output_dim, \n",
    "              hid_dim, \n",
    "              dec_layers, \n",
    "              dec_heads, \n",
    "              dec_pf_dim, \n",
    "              enc_dropout, \n",
    "              device)\n",
    "\n",
    "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6280448\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3688960\n",
      " 25600\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3688960\n",
      " 14410\n",
      "______\n",
      "17696947\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "# increase learning rate due to GPU compute limitations\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
    "\n",
    "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
    "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
    "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_len, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg    = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg    = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_len, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n",
    "\n",
    "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
    "\n",
    "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))\n",
    "test_loader_length  = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 3m 29s\n",
      "\tTrain Loss: 4.184 | Train PPL:  65.641\n",
      "\t Val. Loss: 3.604 |  Val. PPL:  36.728\n",
      "Epoch: 02 | Time: 3m 28s\n",
      "\tTrain Loss: 3.499 | Train PPL:  33.091\n",
      "\t Val. Loss: 3.430 |  Val. PPL:  30.889\n",
      "Epoch: 03 | Time: 3m 28s\n",
      "\tTrain Loss: 3.264 | Train PPL:  26.156\n",
      "\t Val. Loss: 3.323 |  Val. PPL:  27.743\n",
      "Epoch: 04 | Time: 3m 26s\n",
      "\tTrain Loss: 3.096 | Train PPL:  22.115\n",
      "\t Val. Loss: 3.273 |  Val. PPL:  26.398\n",
      "Epoch: 05 | Time: 3m 29s\n",
      "\tTrain Loss: 2.977 | Train PPL:  19.626\n",
      "\t Val. Loss: 3.244 |  Val. PPL:  25.633\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs = 5\n",
    "clip       = 1\n",
    "\n",
    "# name of model - for general attention\n",
    "save_path = f'models/{model.__class__.__name__}_additive.pt'\n",
    "model_name = f'{model.__class__.__name__}_additive.pt'\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "    \n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    #lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.237 | Test PPL:  25.449 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into disk\n",
    "import pickle\n",
    "meta = {\n",
    "    'token_transform': token_transform,\n",
    "    'vocab_transform': vocab_transform,\n",
    "}\n",
    "meta_name = 'meta_additive.pkl'\n",
    "pickle.dump(meta, open('models/meta_additive.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product and geography are what make cream skimming work. '"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ထုတ်ကုန်နှင့် ပထဝီဝင်အနေအထားသည် ခရင်မ် skimming ကို အလုပ်ဖြစ်စေသည်။'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2, 10015,    13,  7836,    16,    76,   101,  3149, 14292,    93,\n",
       "            4,     3], device='cuda:0')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,   700,    21,  3048,  1698,     5,   430,    25,   679,   687,\n",
       "        10186,     6,  1710,   308,     4,     3], device='cuda:0')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12]), torch.Size([1, 16]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 14410])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #batch_size, trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 14410])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 14410])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    7,   154,  1698,     5,   118,    25,   410,   687, 10186,     6,\n",
       "           38,   308,     4,     3,     4], device='cuda:0')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "များ\n",
      "ပတ်သက်\n",
      "အနေအထား\n",
      "သည်\n",
      "အလွန်\n",
      "ရ\n",
      "က်\n",
      "မ်\n",
      "skimming\n",
      "ကို\n",
      "ဖြစ်\n",
      "စေသည်\n",
      "။\n",
      "<eos>\n",
      "။\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 8. Attention - Additive\n",
    "\n",
    "Let's display the attentions to understand how the source text links with the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16, 12])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = attentions[0, 0, :, :]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Product',\n",
       " 'and',\n",
       " 'geography',\n",
       " 'are',\n",
       " 'what',\n",
       " 'make',\n",
       " 'cream',\n",
       " 'skimming',\n",
       " 'work',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'များ',\n",
       " 'ပတ်သက်',\n",
       " 'အနေအထား',\n",
       " 'သည်',\n",
       " 'အလွန်',\n",
       " 'ရ',\n",
       " 'က်',\n",
       " 'မ်',\n",
       " 'skimming',\n",
       " 'ကို',\n",
       " 'ဖြစ်',\n",
       " 'စေသည်',\n",
       " '။',\n",
       " '<eos>',\n",
       " '။']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    #attention = attention.squeeze(1).cpu().detach().toList()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
